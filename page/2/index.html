<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"blog.tongorz.me","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="AhTong&#39;s blog">
<meta property="og:url" content="https://blog.tongorz.me/page/2/index.html">
<meta property="og:site_name" content="AhTong&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Ahtong">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://blog.tongorz.me/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>AhTong's blog</title>
  



  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{&quot;token&quot;: &quot;5e61404f62704823b545b65cc244544a&quot;}'></script>





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">AhTong's blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">但盼风雨来,能留你在此</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">5</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">2</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">35</span></a></li><li class="menu-item menu-item-resources"><a href="/resources/" rel="section"><i class="fa fa-download fa-fw"></i>资源</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Ahtong"
      src="/images/81060761_p0.jpg">
  <p class="site-author-name" itemprop="name">Ahtong</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">35</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/202306236c074e55.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AhTong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AhTong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/202306236c074e55.html" class="post-title-link" itemprop="url">一种用于高光谱图像分类的轻型光谱-空间卷积模块</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-06-23 09:54:45" itemprop="dateCreated datePublished" datetime="2023-06-23T09:54:45+08:00">2023-06-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-06 17:27:52" itemprop="dateModified" datetime="2024-02-06T17:27:52+08:00">2024-02-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《A Lightweight Spectral-Spatial Convolution Module for
Hyperspectral Image Classification》</p>
<h2 id="摘要">摘要</h2>
<p>摘要——卷积神经网络（CNN）在高光谱图像（HSI）分类方面表现出色。
然而，卷积层包含大量参数，这限制了 CNN
在存储和计算资源有限的卫星和机载平台上的部署。
在本篇论文中，我们提出了一种轻量级的光谱空间卷积模块（<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.368ex" height="1.937ex" role="img" focusable="false" viewBox="0 -833.9 3256.6 855.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z"></path></g><g data-mml-node="msup" transform="translate(625,0)"><g data-mml-node="mi"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path></g><g data-mml-node="mn" transform="translate(589,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(1617.6,0)"><path data-c="43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path></g><g data-mml-node="mi" transform="translate(2339.6,0)"><path data-c="4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path></g></g></g></svg></mjx-container></span>）作为卷积层的替代方案。
所提出的<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.368ex" height="1.937ex" role="img" focusable="false" viewBox="0 -833.9 3256.6 855.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z"></path></g><g data-mml-node="msup" transform="translate(625,0)"><g data-mml-node="mi"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path></g><g data-mml-node="mn" transform="translate(589,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(1617.6,0)"><path data-c="43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path></g><g data-mml-node="mi" transform="translate(2339.6,0)"><path data-c="4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path></g></g></g></svg></mjx-container></span>可以在乘法累加运算（MAC）方面大大降低网络参数和计算复杂度，同时保持甚至提高分类性能。
此外，它是一个即插即用组件，可用于升级现有的基于 CNN 的 HSI 分类模型。
两个基准 HSI 数据集的实验结果表明，与其他最先进的方法相比，所提出的<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.368ex" height="1.937ex" role="img" focusable="false" viewBox="0 -833.9 3256.6 855.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z"></path></g><g data-mml-node="msup" transform="translate(625,0)"><g data-mml-node="mi"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path></g><g data-mml-node="mn" transform="translate(589,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(1617.6,0)"><path data-c="43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path></g><g data-mml-node="mi" transform="translate(2339.6,0)"><path data-c="4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path></g></g></g></svg></mjx-container></span>取得了有竞争力的结果。</p>
<h2 id="本文思路">本文思路</h2>
<p>考虑到基于 CNN 的 HSI 分类模型依赖于具有<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="4.023ex" height="1.554ex" role="img" focusable="false" viewBox="0 -665 1778 687"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1278,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g></g></svg></mjx-container></span>内核大小的空间卷积，这在模型大小上非常昂贵。
在本篇论文中，为了减小 CNN
模型的大小，我们提出了一种轻量级的光谱-空间卷积模块（<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.368ex" height="1.937ex" role="img" focusable="false" viewBox="0 -833.9 3256.6 855.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z"></path></g><g data-mml-node="msup" transform="translate(625,0)"><g data-mml-node="mi"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path></g><g data-mml-node="mn" transform="translate(589,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(1617.6,0)"><path data-c="43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path></g><g data-mml-node="mi" transform="translate(2339.6,0)"><path data-c="4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path></g></g></g></svg></mjx-container></span>）作为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="4.023ex" height="1.554ex" role="img" focusable="false" viewBox="0 -665 1778 687"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1278,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g></g></svg></mjx-container></span>空间卷积的替代方案，其灵感来自[18]和[19]。所提出的<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.368ex" height="1.937ex" role="img" focusable="false" viewBox="0 -833.9 3256.6 855.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z"></path></g><g data-mml-node="msup" transform="translate(625,0)"><g data-mml-node="mi"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path></g><g data-mml-node="mn" transform="translate(589,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(1617.6,0)"><path data-c="43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path></g><g data-mml-node="mi" transform="translate(2339.6,0)"><path data-c="4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path></g></g></g></svg></mjx-container></span>旨在执行光谱-空间联合特征提取，并基于廉价的变换操作构建，即逐点卷积和深度卷积。
所提出的模块可以大大减少所需的参数数量，从而降低网络的复杂性，从而可以减轻过度拟合现象并保持甚至提高分类精度。</p>
<h2 id="本文方法">本文方法</h2>
<h3 id="基于-cnn-的-hsi-分类">基于 CNN 的 HSI 分类</h3>
<p>深度学习模型，尤其是 CNN，在 HSI 分类方面表现出色。
一般来说，为了获得良好的分类性能，基于 CNN
的方法将空间上下文信息与光谱信息相结合，以确定每个像素的预测标签
[20]、[21]。
具体来说，在训练和测试阶段，以相应像素为中心的图像块被裁剪并输入 CNN。
它们通过一系列的卷积、池化和全连接层转化为特征向量。 向量被输入到
softmax 层进行分类。 可以通过使用反向传播算法最小化交叉熵损失来优化 CNN
中的所有参数。 基于 CNN 的 HSI
分类模型通常包含大量用于学习判别和抽象特征的卷积 (Conv)
层，从而产生大量参数 [7]。
因此，由于存储和计算资源的限制，很难在卫星和机载平台上部署 CNN。
在本文中，提出了一个<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.368ex" height="1.937ex" role="img" focusable="false" viewBox="0 -833.9 3256.6 855.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z"></path></g><g data-mml-node="msup" transform="translate(625,0)"><g data-mml-node="mi"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path></g><g data-mml-node="mn" transform="translate(589,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mi" transform="translate(1617.6,0)"><path data-c="43" d="M56 342Q56 428 89 500T174 615T283 681T391 705Q394 705 400 705T408 704Q499 704 569 636L582 624L612 663Q639 700 643 704Q644 704 647 704T653 705H657Q660 705 666 699V419L660 413H626Q620 419 619 430Q610 512 571 572T476 651Q457 658 426 658Q322 658 252 588Q173 509 173 342Q173 221 211 151Q232 111 263 84T328 45T384 29T428 24Q517 24 571 93T626 244Q626 251 632 257H660L666 251V236Q661 133 590 56T403 -21Q262 -21 159 83T56 342Z"></path></g><g data-mml-node="mi" transform="translate(2339.6,0)"><path data-c="4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path></g></g></g></svg></mjx-container></span>来代替 Conv
层，它可以有效地减少参数的数量，将在下面详细介绍。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/202306236c074e55.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230507ab927435.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AhTong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AhTong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230507ab927435.html" class="post-title-link" itemprop="url">CBAM：混合注意力机制</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-05-07 14:46:47" itemprop="dateCreated datePublished" datetime="2023-05-07T14:46:47+08:00">2023-05-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-06 17:10:02" itemprop="dateModified" datetime="2024-02-06T17:10:02+08:00">2024-02-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《CBAM: Convolutional Block Attention Module》</p>
<h2 id="摘要">摘要</h2>
<p>我们提出了卷积块注意模块(convolutional Block Attention Module,
CBAM)，这是一种简单而有效的前馈卷积神经网络注意模块。给定一个中间特征图，我们的模块沿着两个独立的维度、通道和空间顺序推断注意力图，然后将注意力图乘以输入特征图以进行自适应特征细化。由于CBAM是一个轻量级和通用的模块，它可以无缝地集成到任何CNN架构中，开销可以忽略不计，并且是端到端可训练的以及基本的CNN。我们通过ImageNet-1K、MS
COCO检测和VOC
2007检测数据集上的大量实验来验证我们的CBAM。我们的实验表明，各种模型的分类和检测性能都有一致的改进，证明了CBAM的广泛适用性。代码和模型将公开。</p>
<h2 id="介绍">介绍</h2>
<p>除了这些因素，我们还研究了架构设计的另一个方面–注意力。注意的意义在以前的文献中已被广泛研究。注意力不仅告诉我们应该把重点放在哪里，它还能改善兴趣的表现。<strong>我们的目标是通过使用注意机制来增加表征能力：专注于重要特征，抑制不必要的特征。</strong>本文提出了一种新的网络模块，称为卷积块注意模块。由于卷积运算通过将跨通道和空间信息混合在一起来提取信息特征，因此我们采用我们的模块来强调沿通道和空间轴这两个主要维度的有意义的特征。为了实现这一点，我们顺序地应用了通道和空间注意模块(如图1所示)，以便每个分支可以分别学习在通道和空间轴上参加什么和在哪里参加。<strong>因此，我们的模块通过学习强调或抑制哪些信息来有效地帮助网络中的信息流动。</strong>
<img src="/article/20230507ab927435/image-20230503142504782.png" class="" title="image-20230503142504782">
在ImageNet-1K数据集中，通过插入我们的小模块，我们从不同的基线网络获得了精度的提高，显示了CBAM的有效性。我们使用GRAD-CAM可视化训练的模型，并观察到CBAM增强网络比其基线网络更恰当地聚焦于目标对象。考虑到这一点，我们推测性能的提升来自于对无关杂波的准确关注和降噪。最后，我们在MS
Coco和VOC
2007数据集上验证了目标检测的性能改进，展示了CBAM的广泛适用性。由于我们精心设计了轻量级的模块，因此在大多数情况下，参数和计算的开销可以忽略不计。
<strong>本文贡献：</strong>我们的主要贡献有三方面。</p>
<ol type="1">
<li>我们提出了一种简单而有效的注意模块(CBAM)，可以广泛应用于提高CNN的表征能力。</li>
<li>我们通过广泛的消融研究来验证我们的注意力模块的有效性。</li>
<li>我们通过插入我们的轻量级模块，验证了在多个基准测试(ImageNet-1K、MS
Coco和VOC 2007)上，各种网络的性能都得到了极大的提高。</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230507ab927435.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230507fcbd5e6b.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AhTong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AhTong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230507fcbd5e6b.html" class="post-title-link" itemprop="url">基于分组多注意力网络的高光谱图像光谱空间分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-05-07 14:46:47" itemprop="dateCreated datePublished" datetime="2023-05-07T14:46:47+08:00">2023-05-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:57:18" itemprop="dateModified" datetime="2024-02-04T21:57:18+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>13 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Grouped Multi-Attention Network for Hyperspectral Image
Spectral-Spatial Classification》</p>
<h2 id="摘要">摘要</h2>
<p>深度学习 (DL) 已成为高光谱图像 (HSI) 分类的强大工具。
然而，由于高维和复杂的光谱空间特征，有效地从 HSI
中学习高度区分的特征仍然是一个悬而未决的问题。
为了解决这个问题，我们提出了一种新的波段分组引导多注意力模块，用于提高光谱空间特征学习的性能。
首先，基于相邻光谱带之间的高相关性和远程光谱带之间的低依赖性这一事实，将所有光谱带自适应地划分为多个不重叠的组，其中包括相关波段。
优点是在处理和分析每组时降低光谱维数和数据复杂度。
然后，将一种不仅探索组内显着信息而且传播组间差异信息的多注意机制嵌入到卷积神经网络
(CNN) 中，以学习组特定的光谱空间特征。
通过强调有用的光谱/空间信息并用注意机制压缩无用信息，增强了学习特征的可分割性。
在此模块的基础上，构建了一个光谱空间分类网络，命名为分组多注意力网络（GMA-Net）。
GMA-Net
包含一个双分支架构，即像素级光谱特征学习和补丁级光谱空间特征学习。
通过融合来自两个分支的特征，可以整合像素级和补丁级学习方式提供的互补和判别特征，以进一步提高分类性能。
实验结果表明，所提出的方法优于几种最先进的方法。
代码位于：https://github.com/luting-hnu。</p>
<h2 id="本文思路">本文思路</h2>
<p><strong>传统方法对数据中有用和无用的信息一视同仁，不管信息是否有用。很可能会引入一些无用的信息，导致分类精度的降低和计算资源的浪费。</strong>最近，视觉注意力机制在增强图像分类结果方面表现出了良好的性能，也被引入到光谱和空间特征提取过程[46]，[47]，[48]中作为一种有效的特征优化方法。这种注意机制突出了对包含最有价值信息的特征的敏感性，这有助于学习判别特征以获得更准确的分类。
大多数基于注意力的方法一次处理所有光谱波段，以掌握全局代表性特征，而忽略了光谱分布信息和光谱反射率特征。即相邻波段之间具有较高的光谱相关性，而远距离波段之间具有较低的相关性;同时，不同波段的光谱反射率特性对不同材料的分类也很敏感。<strong>通过全局注意机制，全局显著特征会被很好地学习，而一些局部显著特征可能会被削弱，从而导致一些重要的区分信息没有足够的关注，这些信息对识别缺乏足够关注的类别有用。</strong>为了克服上述限制，我们设计了一种新颖的分组多注意力驱动深度学习网络，以增强
HSI
分类的特征区分能力。具体而言，所提出的深度学习网络采用了双分支结构，包括基于像素的光谱特征学习分支和基于patch的空间-光谱特征学习分支。对于基于像素级的分支，它以高光谱像素作为输入，并使用具有1×1卷积核的多个卷积层来丰富光谱特征。另一个分支是基于patch的空间-光谱特征提取分支，它以高光谱
patch
作为输入，通过一个先进的band-grouping引导的多注意力模块提取光谱-空间特征。
为此，我们首先在基于patch的空间-光谱特征学习分支中使用了自适应分组机制，将光谱波段自适应地分成多个组。
然后，在每个组中，设计光谱和空间注意模块来加权权衡输入数据的重要性，即强调重要的光谱带和空间像素以提取光谱空间特征。最后，通过全连接网络将这些基于patch的光谱-空间特征与像素的光谱特征相耦合，并通过Softmax函数用于预测类别标签。我们将所提出方法的主要贡献总结如下。</p>
<ol type="1">
<li>在基于DL的HSI分类方法中首次引入了对高度相关相邻波段进行自适应分组的机制。其动机是由于某些物质的判别信息通常包含在一个或几个光谱范围内（例如，绿色植物对红色和近红外波段敏感）。与处理所有波段相比，分组特征提取可以减轻许多不重要波段的影响。</li>
<li>我们提出了一种新颖的多注意力模块用于分组特征提取，以使网络更加关注少数关键和有价值的光谱和空间信息。为此，我们分别构建了光谱注意力和空间注意力块。前者利用组内光谱相关性生成光谱注意力权重。后者不仅利用像素组内显著信息，还充分利用它们之间的组间通信，更好地刻画空间像素的重要性。</li>
<li>本工作中，我们开发了一种新的双分支网络架构用于高光谱图像分类。其中一个分支负责使用CNN和多注意力模块学习高度区分的光谱-空间特征。另一个分支提供由空间卷积引入的互补光谱信息。来自两个分支的特征被融合以提升最终的分类性能。我们对知名的高光谱图像进行了各种实验，以确认所提方法的有效性。</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230507fcbd5e6b.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230506f9739320.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AhTong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AhTong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230506f9739320.html" class="post-title-link" itemprop="url">Remixmatch：具有分布对齐和增强锚定的半监督学习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-05-06 11:12:43" itemprop="dateCreated datePublished" datetime="2023-05-06T11:12:43+08:00">2023-05-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-06 17:00:15" itemprop="dateModified" datetime="2024-02-06T17:00:15+08:00">2024-02-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>15 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《ReMixMatch: Semi-Supervised Learning with Distribution
Matching and Augmentation Anchoring》</p>
<h2 id="摘要">摘要</h2>
<p>我们通过引入两种新技术改进了最近提出的“MixMatch”半监督学习算法：分布对齐和增强锚定。
<strong>分布对齐鼓励未标记数据的预测边缘分布接近真实标签的边缘分布。
增强锚定将输入的多个强增强版本提供给模型，并鼓励每个输出接近同一输入的弱增强版本的预测。</strong>为了产生强大的增强，我们提出了
AutoAugment 的变体，它在训练模型时学习增强策略。 我们称为 ReMixMatch
的新算法比之前的工作具有更高的数据效率，需要 5 倍到 16
倍的数据才能达到相同的精度。 例如，在带有 250 个标记示例的 CIFAR10
上，我们达到了 93.73% 的准确率（相比之下，MixMatch 的准确率为
93.58%，带有 4,000 个示例），而每个类别只有四个标签的准确率中值为
84.92%。 我们在 https://github.com/google-research/remixmatch
上开源我们的代码和数据。</p>
<h2 id="本文思路">本文思路</h2>
<p>半监督学习 (SSL)
提供了一种在只有有限的标记数据可用时利用未标记数据来提高模型性能的方法。
当标记数据昂贵或不方便时，这可以启用大型、强大的模型。 SSL
研究产生了多种方法，包括一致性正则化（Sajjadi 等人，2016 年；Laine 和
Aila，2017
年），它鼓励模型在输入受到扰动时产生相同的预测，以及熵最小化（Grandvalet
和 Bengio， 2005）鼓励模型输出高置信度的预测。
最近提出的“MixMatch”算法（Berthelot 等人，2019
年）将这些技术结合在一个统一的损失函数中，并在各种图像分类基准上实现了强大的性能。
在本文中，我们提出了两项可以轻松集成到 MixMatch 框架中的改进。</p>
<ol type="1">
<li>首先，我们引入了“分布对齐”，<strong>它鼓励模型的聚合类预测的分布与基本真相类标签的边际分布相匹配。</strong>Bridle等人(1992)引入了这个概念作为“公平”目标，其中一个相关的损失项显示出来自模型输入和输出之间相互信息的最大化。在回顾了这个理论框架之后，我们将展示如何通过使用模型预测的运行平均值修改“猜测的标签”来直接将分布对齐添加到MixMatch中。</li>
<li>其次，我们引入了“增强锚定”，它取代了MixMatch的一致性正则化组件<strong>。对于每个给定的未标记输入，增强锚定首先生成一个弱增强版本(例如，只使用翻转和裁剪)，然后生成多个强增强版本。该模型对弱增强输入的预测被视为所有强增强版本的猜测标签的基础。</strong>
为了产生强大的增强，我们引入了一种基于控制理论的 AutoAugment 变体（Cubuk
等人，2018 年），我们称之为“CTAugment”。 与 AutoAugment 不同，CTAugment
在模型训练的同时学习增强策略，使其在 SSL 设置中特别方便。</li>
</ol>
<p>我们将改进后的算法称为“ReMixMatch”，并在一套标准SSL图像基准测试上对其进行实验验证。</p>
<h2 id="相关背景">相关背景</h2>
<p>半监督学习算法的目标是以提高标记数据性能的方式从未标记数据中学习。
实现这一目标的典型方法包括针对未标记数据的“猜测”标签进行训练，或优化不依赖于标签的启发式目标。
<strong>一致性正规化：</strong>许多 SSL
方法依赖于一致性正则化来强制模型输出在输入受到扰动时保持不变。最常见的扰动是应用特定领域的数据增强，用于衡量一致性的损失函数通常是模型针对扰动和非扰动输入的输出之间的均方误差或交叉熵。
<strong>熵最小化：</strong>Grandvalet &amp; Bengio (2005)
认为应该使用未标记的数据来确保类被很好地分离。
这可以通过鼓励模型的输出分布对未标记数据具有低熵（即做出“高置信度”预测）来实现。例如，可以显式地添加一个损失项，以最小化模型在未标记数据上预测的类分布的熵(Grandvalet
&amp; Bengio, 2005;Miyato et al., 2018)。
<strong>标准正则化：</strong>在SSL设置之外，在过度参数化的情况下对模型进行正则化通常是有用的。在对有标签和无标签数据进行训练时，通常都可以应用这种正则化。例如，标准的“权重衰减”（Hinton
&amp; van Camp，1993），其中参数的 L2 范数被最小化，通常与 SSL
技术一起使用。 同样，强大的 MixUp 正则化 (Zhang et al., 2017)
最近已应用于 SSL（Berthelot et al., 2019；Verma et al.,
2019），该模型训练输入和标签的线性插值模型。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230506f9739320.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230420c8f18707.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AhTong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AhTong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230420c8f18707.html" class="post-title-link" itemprop="url">基于注意力的双向长短期记忆网络的高光谱图像分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-20 16:16:17" itemprop="dateCreated datePublished" datetime="2023-04-20T16:16:17+08:00">2023-04-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:49:06" itemprop="dateModified" datetime="2024-02-04T21:49:06+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Hyperspectral Image Classification Using Attention-Based
Bidirectional Long Short-Term Memory Network》</p>
<h2 id="摘要">摘要</h2>
<p>深度神经网络已广泛应用于高光谱图像（HSI）分类领域，其中递归神经网络（RNN）是最典型的网络之一。
大多数现有的基于 RNN
的分类器将像素的光谱特征视为有序序列，其中仅考虑沿相邻波段波长方向的单向相关性。
然而，每个波段图像不仅与其之前的波段图像相关，而且与其连续的波段图像相关。
为了充分探索 HSI 中的这种双向光谱相关性，在本文中，为 HSI
分类设计了一个基于双向长短期记忆 (Bi-LSTM) 的网络。 此外，在所提出的
Bi-LSTM
网络中设计并实现了一种空间-光谱注意机制，以强调有效信息并减少像素空间-光谱上下文中的冗余信息，从而大大提高分类性能。
三个基准 HSI（即Salinas Valley、Pavia Centre和Pavia
University）的实验结果表明，我们提出的 Bi-LSTM
明显优于几种最先进的基于单向 RNN 的分类算法。
此外，所提出的空间-光谱注意机制可以通过有效地加权像素的空间和光谱上下文来进一步提高我们提出的
Bi-LSTM 算法的分类精度。 拟议的 Bi-LSTM 算法的源代码可在
https://github.com/MeiShaohui/Attention-basedBidirectional-LSTM-Network
获得。</p>
<h2 id="主要问题">主要问题</h2>
<ol type="1">
<li>现有的基于rnn的工作主要是将一个HSI的每个像素作为沿光谱方向的有序序列，无法充分探索一个HSI内的光谱相似性。</li>
<li>分类任务中至关重要的像素空间上下文不能直接用于传统的
RNN。尽管已经使用双向卷积 LSTM 进行空间-光谱特征学习以对 HSI 进行分类
[53]，但由于空间特征和光谱特征是单独探索并连接起来进行分类的，因此没有得到很好的探索。</li>
</ol>
<h2 id="解决方法">解决方法</h2>
<ol type="1">
<li>使用Bi-LSTM网络来考虑波段图像的双向相关性，其中同时考虑前向和后向相关性来对
HSI 进行分类。</li>
<li>设计了一种空间-光谱注意机制，以强调像素的空间-光谱上下文之间的有效信息，削弱冗余信息，通过该机制对像素的空间和光谱上下文进行加权，以缓解光谱变化。</li>
</ol>
<h2 id="本文方法">本文方法</h2>
<h3 id="bi-lstm的体系结构">Bi-LSTM的体系结构</h3>
<img src="/article/20230420c8f18707/image-20230418110319575.png" class="" title="image-20230418110319575">
<p>如图 1 所示，在所提出的基于 Bi-LSTM 的 HSI
分类策略中，原始高光谱数据首先使用分块和归一化进行预处理，然后依次馈送到空间光谱注意模块和
Bi-LSTM 预测模块。
在注意力模块中，融合了空间-光谱信息，通过注意力机制对像素的空间和光谱上下文进行加权，以减轻光谱变化。
同时，它允许网络处理 3-D 输入，从而在仅支持 2-D 数据输入的传统 LSTM
和具有 3 个维度的 HSI 数据之间建立了桥梁。 在 Bi-LSTM
预测模块中，通过同时探索沿谱维度的前向和后向相关性来进行特征提取。
最后，提取的空间-光谱联合特征使用经典的 softmax 分类器进行分类。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230420c8f18707.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230409d162546.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AhTong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AhTong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230409d162546.html" class="post-title-link" itemprop="url">SoftMatch：解决半监督学习中的数量-质量权衡问题</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-10 00:24:38" itemprop="dateCreated datePublished" datetime="2023-04-10T00:24:38+08:00">2023-04-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-09 18:54:21" itemprop="dateModified" datetime="2024-02-09T18:54:21+08:00">2024-02-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《SoftMatch: Addressing the Quantity-Quality Tradeoff in
Semi-supervised Learning》</p>
<h2 id="主要问题">主要问题</h2>
<ol type="1">
<li>SSL的主要挑战在于如何有效地利用未标记数据的信息来提高模型的泛化性能。</li>
<li>具有置信度阈值的伪标记非常成功并被广泛采用，基于阈值的伪标签的核心思想是用预测置信度高于硬阈值的伪标签来训练模型，而其他的则被简单地忽略。然而，这种机制固有地表现出数量与质量的权衡，这破坏了学习过程。例如，FixMatch
中利用的高置信度阈值确保了伪标签的质量。然而，它丢弃了大量不自信但正确的伪标签。</li>
<li>动态增长的阈值或类阈值鼓励使用更多的伪标签，但不可避免地会完全使用可能误导训练的错误伪标签。例如，FlexMatch。</li>
</ol>
<p>综上所述，具有置信度阈值的数量-质量权衡限制了未标记数据的利用率，这可能会阻碍模型的泛化性能。</p>
<p><strong>解决方法：</strong></p>
<ol type="1">
<li>所以作者提出softmatch的方法，采用截断高斯函数。根据我们对边缘分布的假设，采用一个截断的高斯函数来拟合置信度分布，该置信度分布根据伪标签的置信度与高斯均值的偏差，为可能正确的伪标签分配较低的权重。</li>
<li>通过统一对齐的方法来解决伪标签类不平衡的问题。</li>
</ol>
<h2 id="主要方法">主要方法</h2>
<p>我们正式定义了 SSL
中伪标签的数量和质量，并从统一样本权重公式的角度总结了先前方法中存在的固有权衡。我们首先确定数量-质量权衡背后的根本原因是缺乏加权函数对伪标签分布施加的复杂假设。其中，置信度阈值可以看作是根据样本的置信度分配二元权重的阶梯函数，它假设置信度高于阈值的伪标签是正确的，而其他伪标签是错误的。在分析的基础上，我们提出了SoftMatch来克服这种权衡，在训练过程中保持高数量和高质量的伪标签。根据我们对边缘分布的假设，采用一个截断的高斯函数来拟合置信度分布，该置信度分布根据伪标签的置信度与高斯均值的偏差，为可能正确的伪标签分配较低的权重。高斯函数的参数是在训练期间使用模型的历史预测来估计的。此外，我们提出了统一对齐的方法来解决伪标签中由于不同类别的学习困难而导致的不平衡问题。它进一步巩固了伪标签的数量，同时保持了伪标签的质量。在图1(c)和图1(b)所示的Two-Moon数据集中，SoftMatch获得了明显更好的伪标签精度，同时在训练过程中保持了始终较高的伪标签利用率，因此，可以获得如图1(d)所示的更好的学习决策边界。
<img src="/article/20230409d162546/image-20230407110309626.png" class="" title="image-20230407110309626"> 贡献可以概括为：</p>
<ol type="1">
<li>我们通过正式定义伪标签的数量和质量，以及它们之间的权衡，证明了统一加权函数的重要性。我们发现，以前的方法中固有的权衡主要源于对伪标签分布缺乏仔细的设计，这是由加权函数直接施加的。</li>
<li>我们提出了SoftMatch，以有效地利用低置信度但正确的伪标签，将截断的高斯函数拟合为置信度分布，从而克服了权衡。我们进一步提出统一对齐来解决假标签的不平衡问题，同时保持其高数量和高质量。</li>
<li>我们证明了SoftMatch在各种图像和文本评估设置上优于以前的方法。我们还通过经验验证了在SSL中追求更好的无标签数据利用率的同时保持伪标签的高精度的重要性。</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230409d162546.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230406ecc22411.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AhTong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AhTong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230406ecc22411.html" class="post-title-link" itemprop="url">用于高光谱图像分类的基于深度神经网络的相关潜在表示学习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-06 18:10:57" itemprop="dateCreated datePublished" datetime="2023-04-06T18:10:57+08:00">2023-04-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:35:46" itemprop="dateModified" datetime="2024-02-04T21:35:46+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Deep neural networks-based relevant latent representation
learning for hyperspectral image classification》</p>
<h2 id="主要问题">主要问题</h2>
<ol type="1">
<li>大量的光谱波段和较少的训练样本导致了维数诅咒的问题，很难得到准确的分类。</li>
<li>大多数的频谱空间特征提取方法都是将频谱矢量与邻近区域进行拼接或平均。然而，有些特征对分类没有用处，可能有噪声，导致在采用少量标记数据时表现不佳。</li>
</ol>
<h2 id="主要方法">主要方法</h2>
<ol type="1">
<li>我们提出了一种新的方法，允许通过保留光谱和空间特征来降低数据的维数，仅使用少量标记样本以改进基于多视图深度表示学习的
HSI 分类。</li>
<li>我们提出了一种无监督多视图深度自动编码器 (MVDAE)
模型，将空间和光谱特征融合到联合潜在表示中，以改进 HSI 的分类。 所提出的
MVDAE
的目的是通过丢弃噪声并找到共享的潜在表示来仅提取有用的特征，这对于分类是有效的。</li>
<li>我们建议开发一种半监督图卷积神经网络
(SSGCN)，以便在卷积层中考虑局部顶点特征和图拓扑，在 HSI
分类中保留光谱空间特征，并使用一组有限的标记训练样本。</li>
</ol>
<h2 id="本文方法">本文方法</h2>
<p>本节详细介绍了所提出的 MV-DNNet 方法，该方法由图 1
所示的三个阶段组成。第一阶段包括基于简单的深度自动编码器 (AE)
提取光谱和空间特征，旨在自动提取相关特征，同时保留 HSI 的空间属性。
在第二阶段，我们开发了一个多视图深度自动编码器 (MVDAE)
来组合两个视图，即光谱和空间特征。 然后，我们构建多视图潜在表示的图形。
它试图通过考虑相邻像素之间的距离来考虑空间特征。
之后，我们提出了一种半监督图卷积网络
(SSGCN)，它在卷积层中集成了图拓扑和局部顶点特征，以通过保留光谱空间特征来改进
HSI 分类。
所提出方法的主要优点是允许自动提取相关光谱和空间特征，并通过使用少量标记样本改进
HSI 分类。 <img src="/article/20230406ecc22411/image-20230405221606565.png" class="" title="image-20230405221606565"></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230406ecc22411.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/202304051f241dff.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AhTong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AhTong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/202304051f241dff.html" class="post-title-link" itemprop="url">基于亲和评分的高光谱图像半监督光谱-空间分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-05 16:32:05" itemprop="dateCreated datePublished" datetime="2023-04-05T16:32:05+08:00">2023-04-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:43:34" itemprop="dateModified" datetime="2024-02-04T21:43:34+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>12 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Semisupervised Spectral–Spatial Classification of
Hyperspectral Imagery With Affinity Scoring》</p>
<h2 id="摘要">摘要</h2>
<p>半监督分类已变得流行，因为它可以利用高光谱图像中有限的先验知识。
然而，光谱内部类别的可变性给任务增加了巨大的挑战。
为了解决这些问题，我们提出了一种基于亲和力评分 (AS) (SCAS)
的新型半监督光谱空间分类方法。AS（Adaptive-Supportive）算法是从模糊逻辑中改进而来，它利用光谱和空间特征的模糊贡献，通过权衡局部类别一致性、光谱相似度和先验知识三个因素进行分类。SCAS方法包括三个主要步骤：超像素分割、半监督分类和修改。
第一步生成超像素并使用它们来保持局部类的一致性。 第二步和第三步分别使用
AS 对超像素进行分类并细化分类图。
实验表明，该方法可以优于一些经典方法和最先进的分类器。</p>
<h2 id="主要问题">主要问题</h2>
<ol type="1">
<li>无监督分类仅通过图像统计在没有任何先验知识的情况下将图像划分为相关的组，但它们不会产生与用户所需类别明确相关的聚类[4]。</li>
<li>然而，监督方法仅通过标记样本学习或训练模型，然后将其应用于未标记样本。它们的有效性在很大程度上取决于训练数据的数量和质量。此外，它们忽略了空间信息，因此容易受到光谱异质性的影响。</li>
<li>另一种方法是主动学习，但它要求用户标记最不确定的像素，因此不是全自动的[4]。</li>
</ol>
<h2 id="本文方法">本文方法</h2>
<p>为了解决上述问题，我们提出了一种基于亲和评分(SCAS)的半监督分类方法。他包括三个主要步骤：超像素分割、半监督分类和修改。首先，对HSI进行超像素分割，然后使用AS算法作为分类器。最后，再次使用AS算法对分类图进行细化，以减少椒盐噪声误差。SCAS基于HSI的局部类别一致性，像素或超像素的类别归属很可能与其邻居的类别一致。捕获到局部类别一致性，即使是粗糙的超像素分割对SCAS也有价值。</p>
<ol type="1">
<li>整个过程的核心是AS，它源自模糊逻辑[11]。
它权衡三个因素：局部类别一致性、光谱相似性和先验知识。
这里的新颖性涉及在它们对分类的贡献中利用模糊性。</li>
<li>AS通过对每个像素在同一区域内进行个别决策的同时，总体上对邻居对像素的影响进行了评分，平衡了区域相似性和像素个性之间的关系。通过利用超像素的特性和重复使用有限的先前知识。</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/202304051f241dff.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230327cbcaae6d.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AhTong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AhTong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230327cbcaae6d.html" class="post-title-link" itemprop="url">基于半监督孪生网络高光谱图像分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-03-27 22:33:21" itemprop="dateCreated datePublished" datetime="2023-03-27T22:33:21+08:00">2023-03-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-20 19:03:55" itemprop="dateModified" datetime="2024-02-20T19:03:55+08:00">2024-02-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>22 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《A Semisupervised Siamese Network for Hyperspectral Image
Classification》</p>
<h2 id="摘要">摘要</h2>
<p>随着高光谱成像技术的发展，高光谱图像（HSI）在分析地面物体类别时变得越来越重要。近年来，得益于海量标注数据，深度学习在多个研究领域取得了一系列突破。然而，标记HSI需要足够的领域知识，并且费时费力。因此，如何有效地将深度学习应用于小标记样本是HSI分类研究的一个重要课题。为了解决这个问题，我们提出了一种半监督孪生网络，将孪生网络嵌入到半监督学习方案中。它集成了自编码器模块和孪生网络，分别研究大量未标记数据中的信息，并用有限的标记样本集对其进行校正，称为3DAES。首先，在大量未标记数据上训练自编码器方法以学习精细表示，创建一个无监督特征。其次，基于这个无监督特征，使用有限的标记样本训练孪生网络，以纠正无监督特征，提高各类别之间的特征可分性。此外，通过训练孪生网络，采用随机抽样方案加速训练并避免各样本类别之间的不平衡。对三个基准HSI数据集的实验一致表明，所提出的3DAES方法在有限的标记样本下具有有效性和鲁棒性。为了复现研究，本研究开发的代码可在https://github.com/ShuGuoJ/3DAES.git上获取。</p>
<h2 id="相关工作">相关工作</h2>
<p><strong>迁移学习：</strong>迁移学习旨在将知识从源域转移到目标域，减少后者中大量标记样本的要求。它主要包括两条技术线——微调和数据分布自适应。
<strong>主动学习：</strong>一般来说，很多标记样本可能是多余的和不必要的，因为可能存在提供相似或相同信息的重复样本。因此，如何利用数据集中有价值的标记样本是主动学习想要解决的问题。<strong>在HSI分类中，大多数主动学习方法[33]，[47]，[48]是基于后验概率，后验概率依赖于另一个分类器来发现那些难以分类和更有价值的概率。</strong>
<strong>孪生网络：</strong>最近，旨在利用样本之间的差异来测量样本相似度的孪生网络引起了各个研究领域研究者的关注。由于样本对的构建可以增加标记样本的数量，因此孪生网络是小型训练集场景的一个很好的候选。<strong>一般采用朴素样本构造方法，遍历样本集中所有可能的组合来生成样本对。然而，标记样本对的增加会加剧分类失衡，最终牺牲分类性能。</strong>
<strong>GAN：</strong>此外，生成对抗网络(GAN)[57]是另一种流行的样本增强方法，它生成接近真实样本的假样本。近年来，生成器和鉴别器的GAN被应用于HSI分类[58]、[59]，以解决小样本标记问题。通过重复对抗学习，GAN中的生成器可以生成更多接近的真实样本，判别器可以更准确地识别假样本。在此过程中，鉴别器可以从真实样本中提取出越来越多的鉴别特征。因此，在对抗性学习之后，它可以看作是HSI的一个特征提取器模块，用分类器对小的标记样本进行微调。<strong>虽然这些基于GAN的方法可以获得更多的样本，但很难精确控制训练和收敛过程。</strong></p>
<h2 id="本文贡献">本文贡献</h2>
<img src="/article/20230327cbcaae6d/image-20230322095535074.png" class="" title="image-20230322095535074">
<p>在这篇文章中，我们提出了一个名为 3DAES
的半监督孪生网络，它集成了自动编码器模块和孪生网络，以研究大量未标记数据中的信息，并分别用有限的标记样本集对其进行校正。
首先，自动编码器方法在大量未标记样本上进行训练以学习细化表示，创建所谓的无监督特征。其次，使用有限的标记样本训练孪生网络来纠正无监督特征，以提高不同类别之间的特征可分离性。
同时，为了加快训练过程，避免样本不平衡，还提出了随机抽样方案。所提出的
3DAES 架构的流程图如图 1 所示。使用三个基准 HSI
数据集进行的实验一致证明了所提出的具有有限标记样本的 3DAES
方法的有效性和稳健性。 <strong>本文主要贡献：</strong></p>
<ol type="1">
<li>我们提出了一个半监督孪生网络，称为 3DAES，用于 HSI 分类。
在孪生网络的训练阶段，样本对的构建可以增加训练数据，但会带来冗余性和多样性，尤其是在标记样本非常有限的情况下。
相反，未标记样本包含丰富的多样性，可以很好地弥补标记样本的不足。
<strong>因此，提出了一个半监督孪生网络来整合双方。
具体来说，我们引入了一个自动编码器模块，它首先使用无监督方法直接从数据本身学习必要的数据表示。
虽然由此产生的无监督特征包含了数据的内部结构信息，但它可能缺乏类可分离性；
因此，我们使用孪生网络提取有限标记样本的关系特征，旨在纠正无监督特征，以减少类内距离，同时增加类间距离。</strong>因此，所提出的
3DAES
方法可以分别充分利用大量未标记数据和有限标记样本中的无监督和监督信息，从而缓解小训练集导致的任何问题。
与现有的半监督方法不同，3DAES
不直接对无监督特征进行微调，而是用小标记样本间接校正。
据我们所知，这是第一次将孪生网络嵌入到 HSI 分类的半监督学习框架中。</li>
<li><strong>提出了一种随机抽样策略来加速模型训练并避免预测偏差。</strong>
这种策略也可以被认为是一种数据增强过程，可以使所提出的 3DAES
模型对小训练样本有效。
对于朴素样本构建，负类的数量可能比正类的数量大得多。
在这种情况下，分由于样本在学习过程中的梯度贡献较大，分类模型一般倾向于给样本赋一个负类标签。另外，所提出的<strong>随机抽样方案简单但有效地缓解了正类和负类之间的任何不平衡，并且不需要额外的超参数。</strong>
在每次训练迭代中，正样本和负样本的数量也相等，这显着加快了训练过程。</li>
<li>所提出的 3DAES
框架中每个模块的重要性已通过一系列消融实验得到验证，并且三个基准 HSI
数据集的实验一致证明了所提出方法优于其他方法的有效性。 所提出的 3DAES
框架中包含的超参数可以通过交叉验证确定，交叉验证在每个卷积层中保持不变；
因此，确保了所提出的 3DAES 框架的鲁棒性。 对于研究复制，可以在
https://github.com/ShuGuoJ/3DAES.git 上找到为本研究开发的代码。</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230327cbcaae6d.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/2023032144cd67ca.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AhTong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AhTong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/2023032144cd67ca.html" class="post-title-link" itemprop="url">HyperViTGAN：基于Transformer半监督生成对抗网络的高光谱图像分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-03-21 10:52:23" itemprop="dateCreated datePublished" datetime="2023-03-21T10:52:23+08:00">2023-03-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:21:21" itemprop="dateModified" datetime="2024-02-04T21:21:21+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>16 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《HyperViTGAN: Semi-supervised Generative Adversarial Network
with Transformer for Hyperspectral Image Classification》</p>
<h2 id="摘要">摘要</h2>
<p>近年来，生成对抗网络（GANs）在高光谱图像（HSI）分类中取得了许多优异的成果，因为
GANs 可以有效解决 HSI 分类中训练样本有限的困境。 然而，由于 HSI
数据的类不平衡问题，GAN 总是将少数类样本与假标签相关联。
为了解决这个问题，我们首先提出了一个包含transformer的半监督生成对抗网络，称为HyperViTGAN。
所提出的 HyperViTGAN
设计有一个外部半监督分类器，以避免鉴别器执行分类和鉴别任务时的自相矛盾。
具有跳跃连接的生成器和鉴别器用于通过对抗性学习生成 HSI 补丁。 拟议的
HyperViTGAN 捕获语义上下文和低级纹理以减少关键信息的丢失。
此外，HyperViTGAN 的泛化能力通过使用数据增强得到提升。 在三个著名的 HSI
数据集 Houston 2013、Indian Pines 2010 和 Xuzhou
上的实验结果表明，与当前最先进的分类模型相比，所提出的模型实现了具有竞争力的
HSI 分类性能。</p>
<h2 id="本文思路">本文思路</h2>
<p>尽管GAN 与卷积神经网络 (CNN) 和 RNN 相结合在 HSI
分类中取得了有竞争力的结果，但在针对序列数据的方法仍然存在一些局限性。对于CNN来说，对于类别众多、光谱特征极其相似的HSI，很难很好地捕捉到序列属性，此外，CNN过于关注空间信息，扭曲了频谱上学习特征中的序列信息。以长短期记忆
(LSTM) [34] 和 GRU [35] 为代表的 RNN 是为顺序数据设计的。 RNN
能够像顺序网络一样从顺序数据中提取丰富的上下文语义。然而，RNN
中的有效光谱信息存储在单个碎片神经元中，无法有效保留超长数据依赖性。
此外，顺序网络结构使得难以有效地扩展和并行化 LSTM 和 GRUs
的计算。Transformer [36] 的出现成功解决了 CNN
在捕获远程信息方面的不足。与 RNN 相比，transformer
允许并行计算，这减少了训练时间和由于长期依赖性导致的性能下降。计算两个位置之间的相关性所需的操作次数不会随着距离的增加而增加，其自注意力模块比
CNN 更容易捕获远程信息，使 transformer 成为当今最前沿的模型之一。视觉
Transformer（ViT）[37]表明，Transformer不仅在自然语言处理（NLP）方面表现出色，而且在图像分类方面也取得了出色的性能。当前最先进的Transformer骨干网络在HSI分类领域也表现出了卓越的性能。</p>
<h2 id="本文方法">本文方法</h2>
<p>在本文中，我们首先针对 HSI 分类任务提出了一种基于半监督 GAN
的新型模型 HyperViTGAN，并结合目前用于 HSI 分类的前沿且有前途的
transformer。 三个精心设计的基于高光谱 ViT
的级联元素——生成器、鉴别器和外部分类器——构成了
HyperViTGAN。设计一个具有单个判别输出的判别器和一个具有单个分类输出的外部分类器，可以有效消除当判别器执行分类和判别任务时的自相矛盾。此外，由于HyperViTGAN是专门为HSI设计的，它可以更好地保存频谱序列信息，以避免关键信息的丢失。同时，HyperViTGAN通过数据增强可以获得更好的泛化能力。
本文贡献如下：</p>
<ol type="1">
<li>本文首次提出了一个完全基于transformer的HSI
GAN——HyperViTGAN。HyperViTGAN为单一的判别任务和单一的分类任务分别设计了不同架构的判别器和外部半监督分类器。通过对抗学习和半监督学习，HyperViTGAN可以生成高光谱HSI
patch，同时缓解HSI中类别不平衡的挑战。</li>
<li>设计了级联架构和跳跃连接，用于生成器、判别器和分类器，以提供类似于内存的信息，从而避免关键组件的丢失并提高分类性能。</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/2023032144cd67ca.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Ahtong</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">109k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">6:05</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div><script color="0,0,0" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.icodeq.com/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



  <script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/moment.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/moment-precise-range-plugin@1.3.0/moment-precise-range.min.js"></script>
  <script>
    function timer() {
      var ages = moment.preciseDiff(moment(),moment(20240130100000,"YYYYMMDDhmmss"));
      ages = ages.replace(/years?/, "年");
      ages = ages.replace(/months?/, "月");
      ages = ages.replace(/days?/, "天");
      ages = ages.replace(/hours?/, "小时");
      ages = ages.replace(/minutes?/, "分");
      ages = ages.replace(/seconds?/, "秒");
      ages = ages.replace(/\d+/g, '<span style="color:#1890ff">$&</span>');
      div.innerHTML = `本站已稳定运行 ${ages}`;
    }
    var div = document.createElement("div");
    var copyright = document.querySelector(".copyright");
    document.querySelector(".footer-inner").insertBefore(div, copyright.nextSibling);
    timer();
    setInterval("timer()",1000)
  </script>

  
<script class="next-config" data-name="giscus" type="application/json">{"enable":true,"repo":"7ongOrz/comments","repo_id":"R_kgDOLMZT5A","category":"Announcements","category_id":"DIC_kwDOLMZT5M4CdAO0","mapping":"url","reactions_enabled":1,"emit_metadata":1,"theme":"preferred_color_scheme","lang":"zh-CN","crossorigin":"anonymous","input_position":"top","loading":"lazy"}</script>

<script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.page.comments) return;

  NexT.utils.loadComments('.giscus-container')
    .then(() => NexT.utils.getScript('https://giscus.app/client.js', {
      attributes: {
        async                   : true,
        crossOrigin             : 'anonymous',
        'data-repo'             : CONFIG.giscus.repo,
        'data-repo-id'          : CONFIG.giscus.repo_id,
        'data-category'         : CONFIG.giscus.category,
        'data-category-id'      : CONFIG.giscus.category_id,
        'data-mapping'          : CONFIG.giscus.mapping,
        'data-reactions-enabled': CONFIG.giscus.reactions_enabled,
        'data-emit-metadata'    : CONFIG.giscus.emit_metadata,
        'data-theme'            : CONFIG.giscus.theme,
        'data-lang'             : CONFIG.giscus.lang,
        'data-input-position'   : CONFIG.giscus.input_position,
        'data-loading'          : CONFIG.giscus.loading
      },
      parentNode: document.querySelector('.giscus-container')
    }));
});
</script>

</body>
</html>
