<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"blog.tongorz.me","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Ahtong&#39;s blog">
<meta property="og:url" content="https://blog.tongorz.me/page/2/index.html">
<meta property="og:site_name" content="Ahtong&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Ahtong">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://blog.tongorz.me/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Ahtong's blog</title>
  



  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{&quot;token&quot;: &quot;5e61404f62704823b545b65cc244544a&quot;}'></script>





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Ahtong's blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">但盼风雨来,能留你在此</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">5</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">2</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">32</span></a></li><li class="menu-item menu-item-resources"><a href="/resources/" rel="section"><i class="fa fa-download fa-fw"></i>资源</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Ahtong"
      src="/images/81060761_p0.jpg">
  <p class="site-author-name" itemprop="name">Ahtong</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230507ab927435.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230507ab927435.html" class="post-title-link" itemprop="url">CBAM：混合注意力机制</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-05-07 14:46:47" itemprop="dateCreated datePublished" datetime="2023-05-07T14:46:47+08:00">2023-05-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-06 17:10:02" itemprop="dateModified" datetime="2024-02-06T17:10:02+08:00">2024-02-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《CBAM: Convolutional Block Attention Module》</p>
<h2 id="摘要">摘要</h2>
<p>我们提出了卷积块注意模块(convolutional Block Attention Module,
CBAM)，这是一种简单而有效的前馈卷积神经网络注意模块。给定一个中间特征图，我们的模块沿着两个独立的维度、通道和空间顺序推断注意力图，然后将注意力图乘以输入特征图以进行自适应特征细化。由于CBAM是一个轻量级和通用的模块，它可以无缝地集成到任何CNN架构中，开销可以忽略不计，并且是端到端可训练的以及基本的CNN。我们通过ImageNet-1K、MS
COCO检测和VOC
2007检测数据集上的大量实验来验证我们的CBAM。我们的实验表明，各种模型的分类和检测性能都有一致的改进，证明了CBAM的广泛适用性。代码和模型将公开。</p>
<h2 id="介绍">介绍</h2>
<p>除了这些因素，我们还研究了架构设计的另一个方面–注意力。注意的意义在以前的文献中已被广泛研究。注意力不仅告诉我们应该把重点放在哪里，它还能改善兴趣的表现。<strong>我们的目标是通过使用注意机制来增加表征能力：专注于重要特征，抑制不必要的特征。</strong>本文提出了一种新的网络模块，称为卷积块注意模块。由于卷积运算通过将跨通道和空间信息混合在一起来提取信息特征，因此我们采用我们的模块来强调沿通道和空间轴这两个主要维度的有意义的特征。为了实现这一点，我们顺序地应用了通道和空间注意模块(如图1所示)，以便每个分支可以分别学习在通道和空间轴上参加什么和在哪里参加。<strong>因此，我们的模块通过学习强调或抑制哪些信息来有效地帮助网络中的信息流动。</strong>
<img src="/article/20230507ab927435/image-20230503142504782.png" class="" title="image-20230503142504782">
在ImageNet-1K数据集中，通过插入我们的小模块，我们从不同的基线网络获得了精度的提高，显示了CBAM的有效性。我们使用GRAD-CAM可视化训练的模型，并观察到CBAM增强网络比其基线网络更恰当地聚焦于目标对象。考虑到这一点，我们推测性能的提升来自于对无关杂波的准确关注和降噪。最后，我们在MS
Coco和VOC
2007数据集上验证了目标检测的性能改进，展示了CBAM的广泛适用性。由于我们精心设计了轻量级的模块，因此在大多数情况下，参数和计算的开销可以忽略不计。
<strong>本文贡献：</strong>我们的主要贡献有三方面。</p>
<ol type="1">
<li>我们提出了一种简单而有效的注意模块(CBAM)，可以广泛应用于提高CNN的表征能力。</li>
<li>我们通过广泛的消融研究来验证我们的注意力模块的有效性。</li>
<li>我们通过插入我们的轻量级模块，验证了在多个基准测试(ImageNet-1K、MS
Coco和VOC 2007)上，各种网络的性能都得到了极大的提高。</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230507ab927435.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230507fcbd5e6b.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230507fcbd5e6b.html" class="post-title-link" itemprop="url">基于分组多注意力网络的高光谱图像光谱空间分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-05-07 14:46:47" itemprop="dateCreated datePublished" datetime="2023-05-07T14:46:47+08:00">2023-05-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:57:18" itemprop="dateModified" datetime="2024-02-04T21:57:18+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>13 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Grouped Multi-Attention Network for Hyperspectral Image
Spectral-Spatial Classification》</p>
<h2 id="摘要">摘要</h2>
<p>深度学习 (DL) 已成为高光谱图像 (HSI) 分类的强大工具。
然而，由于高维和复杂的光谱空间特征，有效地从 HSI
中学习高度区分的特征仍然是一个悬而未决的问题。
为了解决这个问题，我们提出了一种新的波段分组引导多注意力模块，用于提高光谱空间特征学习的性能。
首先，基于相邻光谱带之间的高相关性和远程光谱带之间的低依赖性这一事实，将所有光谱带自适应地划分为多个不重叠的组，其中包括相关波段。
优点是在处理和分析每组时降低光谱维数和数据复杂度。
然后，将一种不仅探索组内显着信息而且传播组间差异信息的多注意机制嵌入到卷积神经网络
(CNN) 中，以学习组特定的光谱空间特征。
通过强调有用的光谱/空间信息并用注意机制压缩无用信息，增强了学习特征的可分割性。
在此模块的基础上，构建了一个光谱空间分类网络，命名为分组多注意力网络（GMA-Net）。
GMA-Net
包含一个双分支架构，即像素级光谱特征学习和补丁级光谱空间特征学习。
通过融合来自两个分支的特征，可以整合像素级和补丁级学习方式提供的互补和判别特征，以进一步提高分类性能。
实验结果表明，所提出的方法优于几种最先进的方法。
代码位于：https://github.com/luting-hnu。</p>
<h2 id="本文思路">本文思路</h2>
<p><strong>传统方法对数据中有用和无用的信息一视同仁，不管信息是否有用。很可能会引入一些无用的信息，导致分类精度的降低和计算资源的浪费。</strong>最近，视觉注意力机制在增强图像分类结果方面表现出了良好的性能，也被引入到光谱和空间特征提取过程[46]，[47]，[48]中作为一种有效的特征优化方法。这种注意机制突出了对包含最有价值信息的特征的敏感性，这有助于学习判别特征以获得更准确的分类。
大多数基于注意力的方法一次处理所有光谱波段，以掌握全局代表性特征，而忽略了光谱分布信息和光谱反射率特征。即相邻波段之间具有较高的光谱相关性，而远距离波段之间具有较低的相关性;同时，不同波段的光谱反射率特性对不同材料的分类也很敏感。<strong>通过全局注意机制，全局显著特征会被很好地学习，而一些局部显著特征可能会被削弱，从而导致一些重要的区分信息没有足够的关注，这些信息对识别缺乏足够关注的类别有用。</strong>为了克服上述限制，我们设计了一种新颖的分组多注意力驱动深度学习网络，以增强
HSI
分类的特征区分能力。具体而言，所提出的深度学习网络采用了双分支结构，包括基于像素的光谱特征学习分支和基于patch的空间-光谱特征学习分支。对于基于像素级的分支，它以高光谱像素作为输入，并使用具有1×1卷积核的多个卷积层来丰富光谱特征。另一个分支是基于patch的空间-光谱特征提取分支，它以高光谱
patch
作为输入，通过一个先进的band-grouping引导的多注意力模块提取光谱-空间特征。
为此，我们首先在基于patch的空间-光谱特征学习分支中使用了自适应分组机制，将光谱波段自适应地分成多个组。
然后，在每个组中，设计光谱和空间注意模块来加权权衡输入数据的重要性，即强调重要的光谱带和空间像素以提取光谱空间特征。最后，通过全连接网络将这些基于patch的光谱-空间特征与像素的光谱特征相耦合，并通过Softmax函数用于预测类别标签。我们将所提出方法的主要贡献总结如下。</p>
<ol type="1">
<li>在基于DL的HSI分类方法中首次引入了对高度相关相邻波段进行自适应分组的机制。其动机是由于某些物质的判别信息通常包含在一个或几个光谱范围内（例如，绿色植物对红色和近红外波段敏感）。与处理所有波段相比，分组特征提取可以减轻许多不重要波段的影响。</li>
<li>我们提出了一种新颖的多注意力模块用于分组特征提取，以使网络更加关注少数关键和有价值的光谱和空间信息。为此，我们分别构建了光谱注意力和空间注意力块。前者利用组内光谱相关性生成光谱注意力权重。后者不仅利用像素组内显著信息，还充分利用它们之间的组间通信，更好地刻画空间像素的重要性。</li>
<li>本工作中，我们开发了一种新的双分支网络架构用于高光谱图像分类。其中一个分支负责使用CNN和多注意力模块学习高度区分的光谱-空间特征。另一个分支提供由空间卷积引入的互补光谱信息。来自两个分支的特征被融合以提升最终的分类性能。我们对知名的高光谱图像进行了各种实验，以确认所提方法的有效性。</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230507fcbd5e6b.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230506f9739320.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230506f9739320.html" class="post-title-link" itemprop="url">Remixmatch：具有分布对齐和增强锚定的半监督学习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-05-06 11:12:43" itemprop="dateCreated datePublished" datetime="2023-05-06T11:12:43+08:00">2023-05-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-06 17:00:15" itemprop="dateModified" datetime="2024-02-06T17:00:15+08:00">2024-02-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>15 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《ReMixMatch: Semi-Supervised Learning with Distribution
Matching and Augmentation Anchoring》</p>
<h2 id="摘要">摘要</h2>
<p>我们通过引入两种新技术改进了最近提出的“MixMatch”半监督学习算法：分布对齐和增强锚定。
<strong>分布对齐鼓励未标记数据的预测边缘分布接近真实标签的边缘分布。
增强锚定将输入的多个强增强版本提供给模型，并鼓励每个输出接近同一输入的弱增强版本的预测。</strong>为了产生强大的增强，我们提出了
AutoAugment 的变体，它在训练模型时学习增强策略。 我们称为 ReMixMatch
的新算法比之前的工作具有更高的数据效率，需要 5 倍到 16
倍的数据才能达到相同的精度。 例如，在带有 250 个标记示例的 CIFAR10
上，我们达到了 93.73% 的准确率（相比之下，MixMatch 的准确率为
93.58%，带有 4,000 个示例），而每个类别只有四个标签的准确率中值为
84.92%。 我们在 https://github.com/google-research/remixmatch
上开源我们的代码和数据。</p>
<h2 id="本文思路">本文思路</h2>
<p>半监督学习 (SSL)
提供了一种在只有有限的标记数据可用时利用未标记数据来提高模型性能的方法。
当标记数据昂贵或不方便时，这可以启用大型、强大的模型。 SSL
研究产生了多种方法，包括一致性正则化（Sajjadi 等人，2016 年；Laine 和
Aila，2017
年），它鼓励模型在输入受到扰动时产生相同的预测，以及熵最小化（Grandvalet
和 Bengio， 2005）鼓励模型输出高置信度的预测。
最近提出的“MixMatch”算法（Berthelot 等人，2019
年）将这些技术结合在一个统一的损失函数中，并在各种图像分类基准上实现了强大的性能。
在本文中，我们提出了两项可以轻松集成到 MixMatch 框架中的改进。</p>
<ol type="1">
<li>首先，我们引入了“分布对齐”，<strong>它鼓励模型的聚合类预测的分布与基本真相类标签的边际分布相匹配。</strong>Bridle等人(1992)引入了这个概念作为“公平”目标，其中一个相关的损失项显示出来自模型输入和输出之间相互信息的最大化。在回顾了这个理论框架之后，我们将展示如何通过使用模型预测的运行平均值修改“猜测的标签”来直接将分布对齐添加到MixMatch中。</li>
<li>其次，我们引入了“增强锚定”，它取代了MixMatch的一致性正则化组件<strong>。对于每个给定的未标记输入，增强锚定首先生成一个弱增强版本(例如，只使用翻转和裁剪)，然后生成多个强增强版本。该模型对弱增强输入的预测被视为所有强增强版本的猜测标签的基础。</strong>
为了产生强大的增强，我们引入了一种基于控制理论的 AutoAugment 变体（Cubuk
等人，2018 年），我们称之为“CTAugment”。 与 AutoAugment 不同，CTAugment
在模型训练的同时学习增强策略，使其在 SSL 设置中特别方便。</li>
</ol>
<p>我们将改进后的算法称为“ReMixMatch”，并在一套标准SSL图像基准测试上对其进行实验验证。</p>
<h2 id="相关背景">相关背景</h2>
<p>半监督学习算法的目标是以提高标记数据性能的方式从未标记数据中学习。
实现这一目标的典型方法包括针对未标记数据的“猜测”标签进行训练，或优化不依赖于标签的启发式目标。
<strong>一致性正规化：</strong>许多 SSL
方法依赖于一致性正则化来强制模型输出在输入受到扰动时保持不变。最常见的扰动是应用特定领域的数据增强，用于衡量一致性的损失函数通常是模型针对扰动和非扰动输入的输出之间的均方误差或交叉熵。
<strong>熵最小化：</strong>Grandvalet &amp; Bengio (2005)
认为应该使用未标记的数据来确保类被很好地分离。
这可以通过鼓励模型的输出分布对未标记数据具有低熵（即做出“高置信度”预测）来实现。例如，可以显式地添加一个损失项，以最小化模型在未标记数据上预测的类分布的熵(Grandvalet
&amp; Bengio, 2005;Miyato et al., 2018)。
<strong>标准正则化：</strong>在SSL设置之外，在过度参数化的情况下对模型进行正则化通常是有用的。在对有标签和无标签数据进行训练时，通常都可以应用这种正则化。例如，标准的“权重衰减”（Hinton
&amp; van Camp，1993），其中参数的 L2 范数被最小化，通常与 SSL
技术一起使用。 同样，强大的 MixUp 正则化 (Zhang et al., 2017)
最近已应用于 SSL（Berthelot et al., 2019；Verma et al.,
2019），该模型训练输入和标签的线性插值模型。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230506f9739320.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230420c8f18707.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230420c8f18707.html" class="post-title-link" itemprop="url">基于注意力的双向长短期记忆网络的高光谱图像分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-20 16:16:17" itemprop="dateCreated datePublished" datetime="2023-04-20T16:16:17+08:00">2023-04-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:49:06" itemprop="dateModified" datetime="2024-02-04T21:49:06+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Hyperspectral Image Classification Using Attention-Based
Bidirectional Long Short-Term Memory Network》</p>
<h2 id="摘要">摘要</h2>
<p>深度神经网络已广泛应用于高光谱图像（HSI）分类领域，其中递归神经网络（RNN）是最典型的网络之一。
大多数现有的基于 RNN
的分类器将像素的光谱特征视为有序序列，其中仅考虑沿相邻波段波长方向的单向相关性。
然而，每个波段图像不仅与其之前的波段图像相关，而且与其连续的波段图像相关。
为了充分探索 HSI 中的这种双向光谱相关性，在本文中，为 HSI
分类设计了一个基于双向长短期记忆 (Bi-LSTM) 的网络。 此外，在所提出的
Bi-LSTM
网络中设计并实现了一种空间-光谱注意机制，以强调有效信息并减少像素空间-光谱上下文中的冗余信息，从而大大提高分类性能。
三个基准 HSI（即Salinas Valley、Pavia Centre和Pavia
University）的实验结果表明，我们提出的 Bi-LSTM
明显优于几种最先进的基于单向 RNN 的分类算法。
此外，所提出的空间-光谱注意机制可以通过有效地加权像素的空间和光谱上下文来进一步提高我们提出的
Bi-LSTM 算法的分类精度。 拟议的 Bi-LSTM 算法的源代码可在
https://github.com/MeiShaohui/Attention-basedBidirectional-LSTM-Network
获得。</p>
<h2 id="主要问题">主要问题</h2>
<ol type="1">
<li>现有的基于rnn的工作主要是将一个HSI的每个像素作为沿光谱方向的有序序列，无法充分探索一个HSI内的光谱相似性。</li>
<li>分类任务中至关重要的像素空间上下文不能直接用于传统的
RNN。尽管已经使用双向卷积 LSTM 进行空间-光谱特征学习以对 HSI 进行分类
[53]，但由于空间特征和光谱特征是单独探索并连接起来进行分类的，因此没有得到很好的探索。</li>
</ol>
<h2 id="解决方法">解决方法</h2>
<ol type="1">
<li>使用Bi-LSTM网络来考虑波段图像的双向相关性，其中同时考虑前向和后向相关性来对
HSI 进行分类。</li>
<li>设计了一种空间-光谱注意机制，以强调像素的空间-光谱上下文之间的有效信息，削弱冗余信息，通过该机制对像素的空间和光谱上下文进行加权，以缓解光谱变化。</li>
</ol>
<h2 id="本文方法">本文方法</h2>
<h3 id="bi-lstm的体系结构">Bi-LSTM的体系结构</h3>
<img src="/article/20230420c8f18707/image-20230418110319575.png" class="" title="image-20230418110319575">
<p>如图 1 所示，在所提出的基于 Bi-LSTM 的 HSI
分类策略中，原始高光谱数据首先使用分块和归一化进行预处理，然后依次馈送到空间光谱注意模块和
Bi-LSTM 预测模块。
在注意力模块中，融合了空间-光谱信息，通过注意力机制对像素的空间和光谱上下文进行加权，以减轻光谱变化。
同时，它允许网络处理 3-D 输入，从而在仅支持 2-D 数据输入的传统 LSTM
和具有 3 个维度的 HSI 数据之间建立了桥梁。 在 Bi-LSTM
预测模块中，通过同时探索沿谱维度的前向和后向相关性来进行特征提取。
最后，提取的空间-光谱联合特征使用经典的 softmax 分类器进行分类。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230420c8f18707.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230406ecc22411.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230406ecc22411.html" class="post-title-link" itemprop="url">用于高光谱图像分类的基于深度神经网络的相关潜在表示学习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-06 18:10:57" itemprop="dateCreated datePublished" datetime="2023-04-06T18:10:57+08:00">2023-04-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:35:46" itemprop="dateModified" datetime="2024-02-04T21:35:46+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Deep neural networks-based relevant latent representation
learning for hyperspectral image classification》</p>
<h2 id="主要问题">主要问题</h2>
<ol type="1">
<li>大量的光谱波段和较少的训练样本导致了维数诅咒的问题，很难得到准确的分类。</li>
<li>大多数的频谱空间特征提取方法都是将频谱矢量与邻近区域进行拼接或平均。然而，有些特征对分类没有用处，可能有噪声，导致在采用少量标记数据时表现不佳。</li>
</ol>
<h2 id="主要方法">主要方法</h2>
<ol type="1">
<li>我们提出了一种新的方法，允许通过保留光谱和空间特征来降低数据的维数，仅使用少量标记样本以改进基于多视图深度表示学习的
HSI 分类。</li>
<li>我们提出了一种无监督多视图深度自动编码器 (MVDAE)
模型，将空间和光谱特征融合到联合潜在表示中，以改进 HSI 的分类。 所提出的
MVDAE
的目的是通过丢弃噪声并找到共享的潜在表示来仅提取有用的特征，这对于分类是有效的。</li>
<li>我们建议开发一种半监督图卷积神经网络
(SSGCN)，以便在卷积层中考虑局部顶点特征和图拓扑，在 HSI
分类中保留光谱空间特征，并使用一组有限的标记训练样本。</li>
</ol>
<h2 id="本文方法">本文方法</h2>
<p>本节详细介绍了所提出的 MV-DNNet 方法，该方法由图 1
所示的三个阶段组成。第一阶段包括基于简单的深度自动编码器 (AE)
提取光谱和空间特征，旨在自动提取相关特征，同时保留 HSI 的空间属性。
在第二阶段，我们开发了一个多视图深度自动编码器 (MVDAE)
来组合两个视图，即光谱和空间特征。 然后，我们构建多视图潜在表示的图形。
它试图通过考虑相邻像素之间的距离来考虑空间特征。
之后，我们提出了一种半监督图卷积网络
(SSGCN)，它在卷积层中集成了图拓扑和局部顶点特征，以通过保留光谱空间特征来改进
HSI 分类。
所提出方法的主要优点是允许自动提取相关光谱和空间特征，并通过使用少量标记样本改进
HSI 分类。 <img src="/article/20230406ecc22411/image-20230405221606565.png" class="" title="image-20230405221606565"></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230406ecc22411.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/202304051f241dff.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/202304051f241dff.html" class="post-title-link" itemprop="url">基于亲和评分的高光谱图像半监督光谱-空间分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-04-05 16:32:05" itemprop="dateCreated datePublished" datetime="2023-04-05T16:32:05+08:00">2023-04-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:43:34" itemprop="dateModified" datetime="2024-02-04T21:43:34+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>12 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Semisupervised Spectral–Spatial Classification of
Hyperspectral Imagery With Affinity Scoring》</p>
<h2 id="摘要">摘要</h2>
<p>半监督分类已变得流行，因为它可以利用高光谱图像中有限的先验知识。
然而，光谱内部类别的可变性给任务增加了巨大的挑战。
为了解决这些问题，我们提出了一种基于亲和力评分 (AS) (SCAS)
的新型半监督光谱空间分类方法。AS（Adaptive-Supportive）算法是从模糊逻辑中改进而来，它利用光谱和空间特征的模糊贡献，通过权衡局部类别一致性、光谱相似度和先验知识三个因素进行分类。SCAS方法包括三个主要步骤：超像素分割、半监督分类和修改。
第一步生成超像素并使用它们来保持局部类的一致性。 第二步和第三步分别使用
AS 对超像素进行分类并细化分类图。
实验表明，该方法可以优于一些经典方法和最先进的分类器。</p>
<h2 id="主要问题">主要问题</h2>
<ol type="1">
<li>无监督分类仅通过图像统计在没有任何先验知识的情况下将图像划分为相关的组，但它们不会产生与用户所需类别明确相关的聚类[4]。</li>
<li>然而，监督方法仅通过标记样本学习或训练模型，然后将其应用于未标记样本。它们的有效性在很大程度上取决于训练数据的数量和质量。此外，它们忽略了空间信息，因此容易受到光谱异质性的影响。</li>
<li>另一种方法是主动学习，但它要求用户标记最不确定的像素，因此不是全自动的[4]。</li>
</ol>
<h2 id="本文方法">本文方法</h2>
<p>为了解决上述问题，我们提出了一种基于亲和评分(SCAS)的半监督分类方法。他包括三个主要步骤：超像素分割、半监督分类和修改。首先，对HSI进行超像素分割，然后使用AS算法作为分类器。最后，再次使用AS算法对分类图进行细化，以减少椒盐噪声误差。SCAS基于HSI的局部类别一致性，像素或超像素的类别归属很可能与其邻居的类别一致。捕获到局部类别一致性，即使是粗糙的超像素分割对SCAS也有价值。</p>
<ol type="1">
<li>整个过程的核心是AS，它源自模糊逻辑[11]。
它权衡三个因素：局部类别一致性、光谱相似性和先验知识。
这里的新颖性涉及在它们对分类的贡献中利用模糊性。</li>
<li>AS通过对每个像素在同一区域内进行个别决策的同时，总体上对邻居对像素的影响进行了评分，平衡了区域相似性和像素个性之间的关系。通过利用超像素的特性和重复使用有限的先前知识。</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/202304051f241dff.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/2023032144cd67ca.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/2023032144cd67ca.html" class="post-title-link" itemprop="url">HyperViTGAN：基于Transformer半监督生成对抗网络的高光谱图像分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-03-21 10:52:23" itemprop="dateCreated datePublished" datetime="2023-03-21T10:52:23+08:00">2023-03-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:21:21" itemprop="dateModified" datetime="2024-02-04T21:21:21+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>16 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《HyperViTGAN: Semi-supervised Generative Adversarial Network
with Transformer for Hyperspectral Image Classification》</p>
<h2 id="摘要">摘要</h2>
<p>近年来，生成对抗网络（GANs）在高光谱图像（HSI）分类中取得了许多优异的成果，因为
GANs 可以有效解决 HSI 分类中训练样本有限的困境。 然而，由于 HSI
数据的类不平衡问题，GAN 总是将少数类样本与假标签相关联。
为了解决这个问题，我们首先提出了一个包含transformer的半监督生成对抗网络，称为HyperViTGAN。
所提出的 HyperViTGAN
设计有一个外部半监督分类器，以避免鉴别器执行分类和鉴别任务时的自相矛盾。
具有跳跃连接的生成器和鉴别器用于通过对抗性学习生成 HSI 补丁。 拟议的
HyperViTGAN 捕获语义上下文和低级纹理以减少关键信息的丢失。
此外，HyperViTGAN 的泛化能力通过使用数据增强得到提升。 在三个著名的 HSI
数据集 Houston 2013、Indian Pines 2010 和 Xuzhou
上的实验结果表明，与当前最先进的分类模型相比，所提出的模型实现了具有竞争力的
HSI 分类性能。</p>
<h2 id="本文思路">本文思路</h2>
<p>尽管GAN 与卷积神经网络 (CNN) 和 RNN 相结合在 HSI
分类中取得了有竞争力的结果，但在针对序列数据的方法仍然存在一些局限性。对于CNN来说，对于类别众多、光谱特征极其相似的HSI，很难很好地捕捉到序列属性，此外，CNN过于关注空间信息，扭曲了频谱上学习特征中的序列信息。以长短期记忆
(LSTM) [34] 和 GRU [35] 为代表的 RNN 是为顺序数据设计的。 RNN
能够像顺序网络一样从顺序数据中提取丰富的上下文语义。然而，RNN
中的有效光谱信息存储在单个碎片神经元中，无法有效保留超长数据依赖性。
此外，顺序网络结构使得难以有效地扩展和并行化 LSTM 和 GRUs
的计算。Transformer [36] 的出现成功解决了 CNN
在捕获远程信息方面的不足。与 RNN 相比，transformer
允许并行计算，这减少了训练时间和由于长期依赖性导致的性能下降。计算两个位置之间的相关性所需的操作次数不会随着距离的增加而增加，其自注意力模块比
CNN 更容易捕获远程信息，使 transformer 成为当今最前沿的模型之一。视觉
Transformer（ViT）[37]表明，Transformer不仅在自然语言处理（NLP）方面表现出色，而且在图像分类方面也取得了出色的性能。当前最先进的Transformer骨干网络在HSI分类领域也表现出了卓越的性能。</p>
<h2 id="本文方法">本文方法</h2>
<p>在本文中，我们首先针对 HSI 分类任务提出了一种基于半监督 GAN
的新型模型 HyperViTGAN，并结合目前用于 HSI 分类的前沿且有前途的
transformer。 三个精心设计的基于高光谱 ViT
的级联元素——生成器、鉴别器和外部分类器——构成了
HyperViTGAN。设计一个具有单个判别输出的判别器和一个具有单个分类输出的外部分类器，可以有效消除当判别器执行分类和判别任务时的自相矛盾。此外，由于HyperViTGAN是专门为HSI设计的，它可以更好地保存频谱序列信息，以避免关键信息的丢失。同时，HyperViTGAN通过数据增强可以获得更好的泛化能力。
本文贡献如下：</p>
<ol type="1">
<li>本文首次提出了一个完全基于transformer的HSI
GAN——HyperViTGAN。HyperViTGAN为单一的判别任务和单一的分类任务分别设计了不同架构的判别器和外部半监督分类器。通过对抗学习和半监督学习，HyperViTGAN可以生成高光谱HSI
patch，同时缓解HSI中类别不平衡的挑战。</li>
<li>设计了级联架构和跳跃连接，用于生成器、判别器和分类器，以提供类似于内存的信息，从而避免关键组件的丢失并提高分类性能。</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/2023032144cd67ca.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/202303156ca8c96f.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/202303156ca8c96f.html" class="post-title-link" itemprop="url">基于生成对抗网络和邻域多数投票的高光谱数据半监督分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-03-15 19:09:42" itemprop="dateCreated datePublished" datetime="2023-03-15T19:09:42+08:00">2023-03-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:29:26" itemprop="dateModified" datetime="2024-02-04T21:29:26+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>782</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Semi-Supervised Classification of Hyperspectral Data Based on
Generative Adversarial Networks and Neighborhood Majority Voting》</p>
<h2 id="本文思路">本文思路</h2>
<p>GAN
最近已成为一种流行的深度学习方法，并在许多视觉生成任务中取得了更多成功。因为它可以同时利用未标记的数据和标记数据，它在半监督学习方面取得了巨大突破。然而，GANs通常是为二维图像定制的。在文[7]中，设计了一维GAN来训练高光谱像素的光谱信息，可用于半监督HSIs分类。</p>
<h2 id="高光谱生成对抗网络">高光谱生成对抗网络</h2>
<img src="/article/202303156ca8c96f/image-20230315185620343.png" class="" title="image-20230315185620343">
<p>如图 1 所示，我们通过采用和修改 CNN 架构来设计 GAN。 在一维生成器 G
中，Ful. Con. 是一个全连接层，它以均匀的噪声分布 Z
作为一维输入，但结果被重塑为二维张量，并用作卷积堆栈的开始。 UpSampling
层用于表示反向最大池化以将前层重新缩放到所需的大小。
Conv层是CNN中的卷积层，用于提取输入的特征。 Conv 之后是 Batch
Normalization
层，它通过将每个单元的输入标准化为零均值和单位方差来稳定学习。
最后一层将输出生成的样本，该样本将作为“fake”输入提供给 D。
当模型在所有样本上训练后，D
将包含所有样本的特征，我们可以使用这些提取的特征进行光谱分类。</p>
<h3 id="光谱-空间分类">光谱-空间分类</h3>
<p>当GAN训练完成后，我们将得到训练良好的G，可以生成像真实数据一样的数据，以及训练良好的D，可以包含所有未标记样本的特征。我们使用来自最后一个
Conv 层的鉴别器的卷积特征并构建一个小的 CNN 来分类这些光谱特征。
CNN的输入是通过D模型获得的一维光谱特征。Conv 层是<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="4.023ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 1778 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1278,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g></g></g></svg></mjx-container></span>或<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="4.023ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 1778 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1278,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></g></g></g></svg></mjx-container></span>的一维卷积。卷积层计算输出特征图。
卷积后，我们可以得到特征图。Maxpooling
层可以减少特征图的尺寸，它独立地对输入的每个深度切片进行操作，并在空间上调整其大小。该层将区域的最大值作为输出，然后输出特征图的下采样。CNN
的最后（顶层）层是一个分类器，例如 Softmax
层，它将输出样本所属类别的概率。
在几个特征提取阶段之后，整个网络使用损失函数（例如经典最小二乘输出）通过反向传播过程进行训练。
在 HSI 中，一个像素极有可能与相邻像素属于同一类。
受[11]的启发，我们的方法设计了多数表决策略。 图 1 的步骤 3 说明了在 3×3
窗口中使用相邻像素进行联合分类的示例。 中央测试像素<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.459ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 645 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g></g></g></svg></mjx-container></span>的最终标签可以通过多数表决策略来确定，该策略将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.459ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 645 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g></g></g></svg></mjx-container></span>的标签设置为邻域中标签数最大的标签。</p>
<h3 id="模型架构">模型架构</h3>
<img src="/article/202303156ca8c96f/image-20230315190903003.png" class="" title="image-20230315190903003">

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/202303158330fe06.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/202303158330fe06.html" class="post-title-link" itemprop="url">基于卷积神经网络的半监督学习高光谱图像分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-03-15 15:34:21" itemprop="dateCreated datePublished" datetime="2023-03-15T15:34:21+08:00">2023-03-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 21:14:27" itemprop="dateModified" datetime="2024-02-04T21:14:27+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Semi-Supervised Learning via Convolutional Neural Network for
Hyperspectral Image Classification》</p>
<h2 id="摘要">摘要</h2>
<p>为了利用高光谱图像 (HSI) 中的未标记数据，提出了一种基于卷积神经网络
(CNN) 的简单但有效的半监督学习方法用于 HSI 分类。
首先，我们通过将未标记数据的聚类损失函数与标记数据的 softmax
损失函数相结合来定义损失函数。 在这里，从 CNN
中提取的标记特征不仅用于训练分类器，还提供锚点以通过 K-means
方法初始化一组聚类中心。 然后，使用所有数据联合训练深度网络进行 HSI
分类。 实验结果表明，我们的方法可以取得与传统的基于 CNN
的监督学习方法相比的结果。 同时，我们的方法网络结构简单，易于训练。</p>
<h2 id="本文方法">本文方法</h2>
<p>在本文中，提出了一种通过 CNN 进行 HSI
分类的简单但有效的半监督学习方法。
不同于传统的半监督深度网络方法先使用未标记数据预训练网络，然后采用标记数据微调网络，我们的方法同时使用标记样本和未标记样本训练深度网络。
本文的主要贡献可归纳如下：</p>
<ol type="1">
<li>我们开发了一个损失函数，其中包括分别针对未标记和标记样本的聚类损失项和
softmax 损失项，聚类损失项有助于提供类判别函数。</li>
<li>我们采用从标记样本中提取的一些有限特征作为锚来初始化聚类中心，并使用所有样本优化这个深度网络。
因此，我们的方法可以有效地提取强大的特征，并利用有限的标记样本对高光谱图像进行分类。</li>
</ol>
<h2 id="提出的方法">提出的方法</h2>
<h3 id="网络结构">网络结构</h3>
<img src="/article/202303158330fe06/image-20230315102232773.png" class="" title="image-20230315102232773">
<p>我们方法的网络结构如图1所示，网络输入包括标记和未标记样本，这些样本是从大小为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="9.256ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 4091 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mi" transform="translate(888,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1666,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mi" transform="translate(2554,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(3332,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g></g></g></svg></mjx-container></span>的HSI中裁剪而来的，其中<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.717ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 759 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g></g></g></svg></mjx-container></span>是光谱带的数目，本文将<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container></span>设为9。在卷积过程中，我们可以使用大小为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.376ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 3260 699"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1278,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(1778,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2556,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></svg></mjx-container></span>的核作为卷积核，其中<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.593ex" height="1.532ex" role="img" focusable="false" viewBox="0 -677 704 677"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g></g></g></svg></mjx-container></span>是来自最后一层的输出特征地图的数量。设计的CNN结构包括4个卷积层和一个全连通层，每个卷积层后面都有一个整流线性单元
(ReLU)
层作为激活函数。CNN的输出相应地包含已标记和未标记的特征向量。分类步骤采用Softmax分类器，使用K-means完成半监督聚类过程。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/202303158330fe06.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/20230314a6640cfd.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/article/20230314a6640cfd.html" class="post-title-link" itemprop="url">基于半主动卷积神经网络的高光谱图像分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-03-14 18:32:20" itemprop="dateCreated datePublished" datetime="2023-03-14T18:32:20+08:00">2023-03-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-04 20:57:59" itemprop="dateModified" datetime="2024-02-04T20:57:59+08:00">2024-02-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>10 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>原文：《Semi-Active Convolutional Neural Networks for Hyperspectral
Image Classification》</p>
<h2 id="本文思路">本文思路</h2>
<ol type="1">
<li>HS图像容易出现昂贵且耗时的标签标注问题，同时在分类过程中有大量的未标记数据。如何在调查场景中选择样本，无论是标记还是未标记的，并充分利用它们来扩大深度分类器的能力正在变得更具不可忽略的。</li>
<li>通过根据当前模型的不确定性测量标准主动采样信息像素，包含AL的先进HSI分类算法总是能够减轻对足够标记的需求，并获得比经典分类算法更好的性能。</li>
<li>AL和SSL在HSI分类的背景下整合这两种互补技术并取得了良好的性能，但是一方面，它们对深度分类器的相互影响仍然缺少研究。另一方面，现有的大多数方法都依赖于复杂的特征提取和选择标准设计，这可能会限制它们在更广泛的情况下的实用性和可扩展性。</li>
<li>因此，在本文中，我们提出了一个统一的 SSAL
框架，通过以半主动的方式学习 CNN。</li>
</ol>
<h2 id="本文贡献">本文贡献</h2>
<ol type="1">
<li>设计了一种新的半主动HSI分类框架工作，通过学习半监督CNNSA-CNN，简称SA-CNN，通过迭代的方式主动选择标记数据和未标记数据，允许CNN在有限的标记数据下学习更具区分性的特征。</li>
<li>展示了三种直观但有效的AL调度，通过逐步添加主动选择的训练样本，可以很好地拟合网络训练，进一步使训练后的深度分类器具有更强的数据自适应能力。</li>
</ol>
<h2 id="本文方法">本文方法</h2>
<h3 id="方法总览">方法总览</h3>
<img src="/article/20230314a6640cfd/image-20230324235428694.png" class="" title="image-20230324235428694">
<p>为了进一步消除深度模型对大量标记训练样本的强烈依赖，我们提出了半主动学习框架，即同时主动选择标记和未标记数据，从而可以利用更多的全局数据结构信息
相互关联的监督和伪监督允许以渐进的方式相互促进，如图 2
中的工作流程所示。 此外，我们将提出的 SA-CNN
与针对训练集和测试集之间的数据分布差异而设计的三个 AL
计划相结合，从而使我们的方法能够更好地泛化处理各种 HSI 数据集。
上图框架：我们的网络通过同时利用监督和伪监督信息以渐进的方式进行训练。
在每次迭代中，我们首先主动选择那些基于 SLIC
产生高标签一致性的样本，如绿色标记的超像素，及其伪标签来构建可靠的伪标签集。
然后，我们根据三个建议的Schedule对其余样本进行 AL
过程，这些样本在红色超像素中构成高度不一致的语义。
通过这种方式，我们的框架有望充分利用未标记部分的知识，进一步提高 AL
的效率和有效性，实现半 AL。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/article/20230314a6640cfd.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Ahtong</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">94k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">5:15</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div><script color="0,0,0" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.icodeq.com/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



  <script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/moment.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/moment-precise-range-plugin@1.3.0/moment-precise-range.min.js"></script>
  <script>
    function timer() {
      var ages = moment.preciseDiff(moment(),moment(20240130100000,"YYYYMMDDhmmss"));
      ages = ages.replace(/years?/, "年");
      ages = ages.replace(/months?/, "月");
      ages = ages.replace(/days?/, "天");
      ages = ages.replace(/hours?/, "小时");
      ages = ages.replace(/minutes?/, "分");
      ages = ages.replace(/seconds?/, "秒");
      ages = ages.replace(/\d+/g, '<span style="color:#1890ff">$&</span>');
      div.innerHTML = `本站已稳定运行 ${ages}`;
    }
    var div = document.createElement("div");
    var copyright = document.querySelector(".copyright");
    document.querySelector(".footer-inner").insertBefore(div, copyright.nextSibling);
    timer();
    setInterval("timer()",1000)
  </script>

  
<script class="next-config" data-name="giscus" type="application/json">{"enable":true,"repo":"7ongOrz/comments","repo_id":"R_kgDOLMZT5A","category":"Announcements","category_id":"DIC_kwDOLMZT5M4CdAO0","mapping":"url","reactions_enabled":1,"emit_metadata":1,"theme":"preferred_color_scheme","lang":"zh-CN","crossorigin":"anonymous","input_position":"top","loading":"lazy"}</script>

<script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.page.comments) return;

  NexT.utils.loadComments('.giscus-container')
    .then(() => NexT.utils.getScript('https://giscus.app/client.js', {
      attributes: {
        async                   : true,
        crossOrigin             : 'anonymous',
        'data-repo'             : CONFIG.giscus.repo,
        'data-repo-id'          : CONFIG.giscus.repo_id,
        'data-category'         : CONFIG.giscus.category,
        'data-category-id'      : CONFIG.giscus.category_id,
        'data-mapping'          : CONFIG.giscus.mapping,
        'data-reactions-enabled': CONFIG.giscus.reactions_enabled,
        'data-emit-metadata'    : CONFIG.giscus.emit_metadata,
        'data-theme'            : CONFIG.giscus.theme,
        'data-lang'             : CONFIG.giscus.lang,
        'data-input-position'   : CONFIG.giscus.input_position,
        'data-loading'          : CONFIG.giscus.loading
      },
      parentNode: document.querySelector('.giscus-container')
    }));
});
</script>

</body>
</html>
