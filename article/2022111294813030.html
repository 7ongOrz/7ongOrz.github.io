<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"blog.tongorz.me","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="设置种子 123456def set_seed(args):    random.seed(args.seed) # python的随机性    np.random.seed(args.seed) # np的随机性    torch.manual_seed(args.seed) # torch的CPU随机性，为CPU设置随机种子    if args.n_gpu &gt; 0:        to">
<meta property="og:type" content="article">
<meta property="og:title" content="Fixmatch主要代码注释">
<meta property="og:url" content="https://blog.tongorz.me/article/2022111294813030.html">
<meta property="og:site_name" content="Ahtong&#39;s blog">
<meta property="og:description" content="设置种子 123456def set_seed(args):    random.seed(args.seed) # python的随机性    np.random.seed(args.seed) # np的随机性    torch.manual_seed(args.seed) # torch的CPU随机性，为CPU设置随机种子    if args.n_gpu &gt; 0:        to">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-11-12T01:58:45.000Z">
<meta property="article:modified_time" content="2024-02-03T09:16:21.636Z">
<meta property="article:author" content="Ahtong">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="图像分类">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://blog.tongorz.me/article/2022111294813030.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://blog.tongorz.me/article/2022111294813030.html","path":"article/2022111294813030.html","title":"Fixmatch主要代码注释"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Fixmatch主要代码注释 | Ahtong's blog</title>
  



  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{&quot;token&quot;: &quot;5e61404f62704823b545b65cc244544a&quot;}'></script>





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Ahtong's blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">但盼风雨来,能留你在此</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">5</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">2</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">32</span></a></li><li class="menu-item menu-item-resources"><a href="/resources/" rel="section"><i class="fa fa-download fa-fw"></i>资源</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%BE%E7%BD%AE%E7%A7%8D%E5%AD%90"><span class="nav-number">1.</span> <span class="nav-text">设置种子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gpu%E8%AE%BE%E7%BD%AE"><span class="nav-number">2.</span> <span class="nav-text">GPU设置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86"><span class="nav-number">3.</span> <span class="nav-text">数据集划分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#scheduler"><span class="nav-number">4.</span> <span class="nav-text">scheduler</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6"><span class="nav-number">5.</span> <span class="nav-text">混合精度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8C%87%E6%95%B0%E7%A7%BB%E5%8A%A8%E5%B9%B3%E5%9D%87ema"><span class="nav-number">6.</span> <span class="nav-text">指数移动平均（EMA）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8Fweight-decay"><span class="nav-number">7.</span> <span class="nav-text">权重衰减（Weight Decay）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95"><span class="nav-number">8.</span> <span class="nav-text">核心算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD"><span class="nav-number">9.</span> <span class="nav-text">模型保存与加载</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E8%BF%87%E7%A8%8B"><span class="nav-number">9.1.</span> <span class="nav-text">模型保存过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8A%B6%E6%80%81%E5%AD%97%E5%85%B8state_dict"><span class="nav-number">9.2.</span> <span class="nav-text">状态字典：state_dict：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89save_checkpoint%E4%BF%9D%E5%AD%98%E5%AE%8C%E6%95%B4%E6%A8%A1%E5%9E%8B"><span class="nav-number">9.3.</span> <span class="nav-text">定义save_checkpoint保存完整模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD-checkpoint-%E7%94%A8%E4%BA%8E%E6%8E%A8%E7%90%86%E7%BB%A7%E7%BB%AD%E8%AE%AD%E7%BB%83"><span class="nav-number">9.4.</span> <span class="nav-text">保存和加载 Checkpoint
用于推理&#x2F;继续训练</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%9D%E5%AD%98checkpoint"><span class="nav-number">9.4.1.</span> <span class="nav-text">保存Checkpoint：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8A%A0%E8%BD%BDcheckpoint"><span class="nav-number">9.4.2.</span> <span class="nav-text">加载Checkpoint：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8A%A0%E8%BD%BD%E6%9C%80%E4%BC%98%E6%A8%A1%E5%9E%8B"><span class="nav-number">9.4.3.</span> <span class="nav-text">加载最优模型：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#accuracy"><span class="nav-number">10.</span> <span class="nav-text">accuracy</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Ahtong"
      src="/images/81060761_p0.jpg">
  <p class="site-author-name" itemprop="name">Ahtong</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://blog.tongorz.me/article/2022111294813030.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/81060761_p0.jpg">
      <meta itemprop="name" content="Ahtong">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ahtong's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Fixmatch主要代码注释 | Ahtong's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Fixmatch主要代码注释
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-11-12 09:58:45" itemprop="dateCreated datePublished" datetime="2022-11-12T09:58:45+08:00">2022-11-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-03 17:16:21" itemprop="dateModified" datetime="2024-02-03T17:16:21+08:00">2024-02-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>16 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="设置种子">设置种子</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">set_seed</span>(<span class="params">args</span>):</span><br><span class="line">    random.seed(args.seed) <span class="comment"># python的随机性</span></span><br><span class="line">    np.random.seed(args.seed) <span class="comment"># np的随机性</span></span><br><span class="line">    torch.manual_seed(args.seed) <span class="comment"># torch的CPU随机性，为CPU设置随机种子</span></span><br><span class="line">    <span class="keyword">if</span> args.n_gpu &gt; <span class="number">0</span>:</span><br><span class="line">        torch.cuda.manual_seed_all(args.seed) <span class="comment"># torch的GPU随机性，为所有GPU设置随机种子</span></span><br></pre></td></tr></table></figure>
<ol type="1">
<li>设置随机种子</li>
<li>将种子赋予np</li>
<li>将种子赋予torch</li>
<li>将种子赋予cuda</li>
</ol>
<h2 id="gpu设置">GPU设置</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.local_rank == -<span class="number">1</span>:</span><br><span class="line">    device = torch.device(<span class="string">'cuda'</span>, args.gpu_id)</span><br><span class="line">    args.world_size = <span class="number">1</span></span><br><span class="line">    args.n_gpu = torch.cuda.device_count()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    torch.cuda.set_device(args.local_rank)</span><br><span class="line">    device = torch.device(<span class="string">'cuda'</span>, args.local_rank)</span><br><span class="line">    torch.distributed.init_process_group(backend=<span class="string">'nccl'</span>)</span><br><span class="line">    args.world_size = torch.distributed.get_world_size()</span><br><span class="line">    args.n_gpu = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>根据local_rank决定是否采取分布式。如果local_rank=-1，说明分布式失效；如果local_rank不等于-1，则根据不同的卡配置不同的进程数；获取设备device方便后续将数据和模型加载在上面（代码为.to(device))；初始化设置分布式的后端等。</p>
<p><strong>torch.distributed.barrier()的使用：</strong></p>
<p>①数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.local_rank <span class="keyword">not</span> <span class="keyword">in</span> [-<span class="number">1</span>, <span class="number">0</span>]:</span><br><span class="line">    torch.distributed.barrier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据集</span></span><br><span class="line">labeled_dataset, unlabeled_dataset, test_dataset = DATASET_GETTERS[args.dataset](</span><br><span class="line">    args, <span class="string">'./data'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.local_rank == <span class="number">0</span>:</span><br><span class="line">    torch.distributed.barrier()</span><br></pre></td></tr></table></figure>
<p>有些操作是不需要多卡同时运行的，如数据集和模型的加载。因此，PyTorch对非主进程的卡上面的运行进行了barrier设置。如果是在并行训练非主卡上，其它进行需要先等待主进程读取并缓存数据集，再从缓存中读取数据，以同步不同进程的数据，避免出现数据处理不同步的现象。</p>
<p>②模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.local_rank <span class="keyword">not</span> <span class="keyword">in</span> [-<span class="number">1</span>, <span class="number">0</span>]:</span><br><span class="line">    torch.distributed.barrier()</span><br><span class="line"></span><br><span class="line">model = create_model(args)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.local_rank == <span class="number">0</span>:</span><br><span class="line">    torch.distributed.barrier()</span><br></pre></td></tr></table></figure>
<p>先对其余进程设置一个障碍，等到主进程加载完模型和数据后，再对主进程设置障碍，使所有进程都处于同一“出发线”，最后再同时释放。</p>
<span id="more"></span>
<h2 id="数据集划分">数据集划分</h2>
<p>本代码使用的数据集分为三类：带标签的训练集，不带标签的训练集，测试集。虽然表面上需要一个训练集是“不带标签”的，但是PyTorch并没有直接舍去标签的数据集设置。一开始我在想，如果是我自己来写代码，应该要怎么处理呢？后来发现代码根本没有拘泥于“不带标签”这个事情，因为在返回数据集和标签时，使用“_”直接代替掉标签即可，损失函数也不需要使用标签。</p>
<p>核心API： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">labeled_dataset, unlabeled_dataset, test_dataset = DATASET_GETTERS[args.dataset](args, <span class="string">'./data'</span>)</span><br></pre></td></tr></table></figure></p>
<p>dataset-&gt;cifar.py，发现调用了如下函数（get_cifar10和get_cifar100极其类似，只是数据集分类的类别数不一样而已。下面仅以get_cifar100为例）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">def get_cifar100(args, root):</span><br><span class="line">    # 图像变换</span><br><span class="line">    transform_labeled = transforms.Compose([</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.RandomCrop(size=32,</span><br><span class="line">                              padding=int(32*0.125),</span><br><span class="line">                              padding_mode='reflect'),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=cifar100_mean, std=cifar100_std)])</span><br><span class="line"></span><br><span class="line">    transform_val = transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=cifar100_mean, std=cifar100_std)])</span><br><span class="line">   </span><br><span class="line">    # 数据集设置</span><br><span class="line">    base_dataset = datasets.CIFAR100(</span><br><span class="line">        root, train=True, download=True)</span><br><span class="line"></span><br><span class="line">    train_labeled_idxs, train_unlabeled_idxs = x_u_split(</span><br><span class="line">        args, base_dataset.targets)</span><br><span class="line"></span><br><span class="line">    train_labeled_dataset = CIFAR100SSL(</span><br><span class="line">        root, train_labeled_idxs, train=True,</span><br><span class="line">        transform=transform_labeled)</span><br><span class="line"></span><br><span class="line">    train_unlabeled_dataset = CIFAR100SSL(</span><br><span class="line">        root, train_unlabeled_idxs, train=True,</span><br><span class="line">        transform=TransformFixMatch(mean=cifar100_mean, std=cifar100_std))</span><br><span class="line"></span><br><span class="line">    test_dataset = datasets.CIFAR100(</span><br><span class="line">        root, train=False, transform=transform_val, download=False)</span><br><span class="line"></span><br><span class="line">    return train_labeled_dataset, train_unlabeled_dataset, test_dataset</span><br></pre></td></tr></table></figure>
<p>get_cifar100函数包括两部分：transform的设置和数据集设置。</p>
<p>（1）transform</p>
<p>对于测试集和带标签的训练集，可以根据论文[1]的介绍进行设置。但是对于不带标签的训练集，代码调用了TransformFixMatch类，因为这部分的训练集需要使用弱增强和强增强的方法，两种方法是不同的，所以需要特别设置一个callable的类，能够将两种transform手段凑在一块。当构建dataset调用transform时，可以直接调用call函数，直接返回两个增强手段处理后的图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TransformFixMatch</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, mean, std</span>):</span><br><span class="line">        self.weak = transforms.Compose([</span><br><span class="line">            transforms.RandomHorizontalFlip(),</span><br><span class="line">            transforms.RandomCrop(size=<span class="number">32</span>,</span><br><span class="line">                                  padding=<span class="built_in">int</span>(<span class="number">32</span>*<span class="number">0.125</span>),</span><br><span class="line">                                  padding_mode=<span class="string">'reflect'</span>)])</span><br><span class="line">        self.strong = transforms.Compose([</span><br><span class="line">            transforms.RandomHorizontalFlip(),</span><br><span class="line">            transforms.RandomCrop(size=<span class="number">32</span>,</span><br><span class="line">                                  padding=<span class="built_in">int</span>(<span class="number">32</span>*<span class="number">0.125</span>),</span><br><span class="line">                                  padding_mode=<span class="string">'reflect'</span>),</span><br><span class="line">            RandAugmentMC(n=<span class="number">2</span>, m=<span class="number">10</span>)])</span><br><span class="line">        self.normalize = transforms.Compose([</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize(mean=mean, std=std)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, x</span>):</span><br><span class="line">        weak = self.weak(x)</span><br><span class="line">        strong = self.strong(x)</span><br><span class="line">        <span class="keyword">return</span> self.normalize(weak), self.normalize(strong)</span><br></pre></td></tr></table></figure>
<p>（2）数据索引设置</p>
<p>怎么从原始的CIFAR数据集提取出带标签的训练集和无标签的训练集？注意到PyTorch数据集类有一个函数成员def
<strong>getitem</strong>(self,
index)，核心参数是index，所以我们构建以上两个训练集，本质上是构建训练集对应的索引值。下面是索引生成函数x_u_split的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def x_u_split(args, labels):</span><br><span class="line">    label_per_class = args.num_labeled // args.num_classes</span><br><span class="line">    labels = np.array(labels) #每个label是一个数字</span><br><span class="line">    labeled_idx = []</span><br><span class="line">    unlabeled_idx = np.array(range(len(labels)))</span><br><span class="line">    for i in range(args.num_classes): </span><br><span class="line">        idx = np.where(labels == i)[0] #有[0]是因为np.where得到的是一个tuple,需要把tuple的元素提取出来</span><br><span class="line">        idx = np.random.choice(idx, label_per_class, False) </span><br><span class="line">        labeled_idx.extend(idx)</span><br><span class="line">    labeled_idx = np.array(labeled_idx)</span><br><span class="line">    assert len(labeled_idx) == args.num_labeled</span><br><span class="line"></span><br><span class="line">    if args.expand_labels or args.num_labeled &lt; args.batch_size: </span><br><span class="line">        num_expand_x = math.ceil( #向上取整</span><br><span class="line">            args.batch_size * args.eval_step / args.num_labeled) #等于17</span><br><span class="line"></span><br><span class="line">        #将参数元组的元素数组按水平方向进行叠加</span><br><span class="line">        labeled_idx = np.hstack([labeled_idx for _ in range(num_expand_x)])</span><br><span class="line">    np.random.shuffle(labeled_idx)</span><br><span class="line">    return labeled_idx, unlabeled_idx</span><br></pre></td></tr></table></figure>
<p>每个类带标签数据的个数是均衡的，每个类带标签的数据个数 =
带标签数据总个数//类数，所以，使用一个循环（10个类）。
对于每一个类，找出他们在总数据（labels）中的数据索引，然后将labels（原本是列表）转换为numpy数组。并用random.choice随机选择label_per_class个数据，将他们加入到带标签的数据索引labeled_idx中。
对于不带标签的数据，原文作者使用了所有的数据（包含带标签的数据），所以他的索引为全部数据的索引，unlabeled_idx可以直接对应全体数据。
需要注意的一个点是，args.expand_labels参数作者默认为true的，所以我们要进行数据重复。
或者num_labeled比batch_size还小，则对数组进行扩充。
这里重复的次数num_expand_x为 64（batch_size ）* 1024（eval_step）/ 4000
（num_labeled）=17次 所以带标签的数据为
68000个（每个索引都重复了17次）。</p>
<p>（3）数据集设置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CIFAR100SSL</span>(datasets.CIFAR100):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root, indexs, train=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 transform=<span class="literal">None</span>, target_transform=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 download=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(root, train=train,</span><br><span class="line">                         transform=transform,</span><br><span class="line">                         target_transform=target_transform,</span><br><span class="line">                         download=download)</span><br><span class="line">        <span class="keyword">if</span> indexs <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.data = self.data[indexs]</span><br><span class="line">            self.targets = np.array(self.targets)[indexs]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        img, target = self.data[index], self.targets[index]</span><br><span class="line">        img = Image.fromarray(img)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.target_transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            target = self.target_transform(target)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img, target</span><br></pre></td></tr></table></figure>
<h2 id="scheduler">scheduler</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_cosine_schedule_with_warmup</span>(<span class="params">optimizer,</span></span><br><span class="line"><span class="params">                                    num_warmup_steps,</span></span><br><span class="line"><span class="params">                                    num_training_steps,</span></span><br><span class="line"><span class="params">                                    num_cycles=<span class="number">7.</span>/<span class="number">16.</span>,</span></span><br><span class="line"><span class="params">                                    last_epoch=-<span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_lr_lambda</span>(<span class="params">current_step</span>):</span><br><span class="line">        <span class="keyword">if</span> current_step &lt; num_warmup_steps:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">float</span>(current_step) / <span class="built_in">float</span>(<span class="built_in">max</span>(<span class="number">1</span>, num_warmup_steps))</span><br><span class="line">        no_progress = <span class="built_in">float</span>(current_step - num_warmup_steps) / \</span><br><span class="line">            <span class="built_in">float</span>(<span class="built_in">max</span>(<span class="number">1</span>, num_training_steps - num_warmup_steps))</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(<span class="number">0.</span>, math.cos(math.pi * num_cycles * no_progress))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> LambdaLR(optimizer, _lr_lambda, last_epoch)</span><br><span class="line"><span class="comment"># LambdaLR设置学习率为初始学习率乘以给定lr_lambda函数的值</span></span><br><span class="line"><span class="comment"># 当last_epoch=-1时, base_lr为optimizer优化器中的lr</span></span><br><span class="line"><span class="comment"># 每次执行 scheduler.step(),  last_epoch=last_epoch +1</span></span><br></pre></td></tr></table></figure>
<p>scheduler是为了动态调整训练期间的学习率，使模型更好地收敛。论文使用的是带有warmup性质的余弦退火学习率调整器。核心是返回了一个自定义函数的学习率调整器，调整的函数是_lr_lambda，如果当前的step少于warmup的步数，则使用线性递增的策略一直增加到初始学习率；而后使用余弦变化的策略改变学习率:
<span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.602ex;" xmlns="http://www.w3.org/2000/svg" width="15.563ex" height="4.701ex" role="img" focusable="false" viewBox="0 -1370 6878.8 2078"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(530,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1211.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2267.1,0)"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(944,0)"></path></g><g data-mml-node="mo" transform="translate(3605.1,0)"><path data-c="2061" d=""></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3771.8,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mfrac" transform="translate(389,0)"><g data-mml-node="mrow" transform="translate(369,676)"><g data-mml-node="mn"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mi" transform="translate(1070,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(500,0)"></path></g><g data-mml-node="mi" transform="translate(1000,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g></g><rect width="2089" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(2718,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></svg></mjx-container></span> <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="1.124ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 497 658"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>是初始学习率，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.179ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 521 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></svg></mjx-container></span>是当前的步数，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.011ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 889 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g></g></g></svg></mjx-container></span>是总步数。</p>
<h2 id="混合精度">混合精度</h2>
<p>本代码使用的是英伟达开发的apex库，可以通过使用混合精度，在保证精度丢失很少的情况下，减少内存，增快训练速度。混合精度涉及对模型和优化器的重初始化、损失函数的反向传播等。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> apex <span class="keyword">import</span> amp</span><br><span class="line">model, optimizer = amp.initialize(model, optimizer, opt_level=args.opt_level)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> amp.scale_loss(loss, optimizer) <span class="keyword">as</span> scaled_loss:</span><br><span class="line">    scaled_loss.backward()</span><br></pre></td></tr></table></figure>
<h2 id="指数移动平均ema">指数移动平均（EMA）</h2>
<p>EMA在本代码是用于更新模型权重的，核心公式就这一条： <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="21.597ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9545.9 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(518,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1101,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2156.8,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="msub" transform="translate(2722.8,0)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="TeXAtom" transform="translate(518,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4672,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(5672.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(6061.2,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(6783.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(7783.7,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mo" transform="translate(8349.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="msub" transform="translate(8738.7,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g></svg></mjx-container></span> 这里的参数<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.097ex" height="1.027ex" role="img" focusable="false" viewBox="0 -443 485 454"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g></g></g></svg></mjx-container></span>代表测试用模型的参数权重。训练时，原模型就按照正常的节奏来训练、更新权重，而另外开辟一个EMA模型，在原模型更新权重的同时也跟着更新权重，并作为最后使用的模型，检测在测试集上的表现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ModelEMA</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args, model, decay</span>):</span><br><span class="line">        self.ema = deepcopy(model)</span><br><span class="line">        self.ema.to(args.device)</span><br><span class="line">        self.ema.<span class="built_in">eval</span>()</span><br><span class="line">        self.decay = decay</span><br><span class="line">        self.ema_has_module = <span class="built_in">hasattr</span>(self.ema, <span class="string">'module'</span>)</span><br><span class="line">        <span class="comment"># Fix EMA. https://github.com/valencebond/FixMatch_pytorch thank you!</span></span><br><span class="line">        self.param_keys = [k <span class="keyword">for</span> k, _ <span class="keyword">in</span> self.ema.named_parameters()]</span><br><span class="line">        self.buffer_keys = [k <span class="keyword">for</span> k, _ <span class="keyword">in</span> self.ema.named_buffers()]</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> self.ema.parameters():</span><br><span class="line">            p.requires_grad_(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, model</span>): <span class="comment"># 核心模块</span></span><br><span class="line">        <span class="comment"># hasattr函数用于判断对象是否包含对应的属性。</span></span><br><span class="line">        needs_module = <span class="built_in">hasattr</span>(model, <span class="string">'module'</span>) <span class="keyword">and</span> <span class="keyword">not</span> self.ema_has_module</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            msd = model.state_dict() <span class="comment"># torch.nn.Module模块中的state_dict变量存放训练过程中需要学习的权重</span></span><br><span class="line">            esd = self.ema.state_dict()</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> self.param_keys:</span><br><span class="line">                <span class="keyword">if</span> needs_module:</span><br><span class="line">                    j = <span class="string">'module.'</span> + k</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    j = k</span><br><span class="line">                model_v = msd[j].detach()</span><br><span class="line">                ema_v = esd[k]</span><br><span class="line">                <span class="comment"># ema_v是过去的平均状态，model_v是现在的参数</span></span><br><span class="line">                esd[k].copy_(ema_v * self.decay + (<span class="number">1.</span> - self.decay) * model_v)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> self.buffer_keys:</span><br><span class="line">                <span class="keyword">if</span> needs_module:</span><br><span class="line">                    j = <span class="string">'module.'</span> + k</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    j = k</span><br><span class="line">                esd[k].copy_(msd[j])</span><br></pre></td></tr></table></figure>
<h2 id="权重衰减weight-decay">权重衰减（Weight Decay）</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">grouped_parameters = [</span><br><span class="line">        <span class="comment"># 若网络层不包含 bias 或 BatchNorm，则应用 weight_decay</span></span><br><span class="line">        <span class="comment"># any() 函数用于判断给定的可迭代参数 iterable 是否全部为 False，则返回 False，如果有一个为 True，则返回 True</span></span><br><span class="line">        {<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">any</span>(</span><br><span class="line">            nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: args.wdecay},</span><br><span class="line">        <span class="comment"># 反之，则不用 weight_decay</span></span><br><span class="line">        {<span class="string">'params'</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> <span class="built_in">any</span>(</span><br><span class="line">            nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)], <span class="string">'weight_decay'</span>: <span class="number">0.0</span>}</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure>
<h2 id="核心算法">核心算法</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">labeled_iter = <span class="built_in">iter</span>(labeled_trainloader)</span><br><span class="line">unlabeled_iter = <span class="built_in">iter</span>(unlabeled_trainloader)</span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.start_epoch, args.epochs):</span><br><span class="line">    <span class="comment"># 平均处理器，用于存储一些统计信息</span></span><br><span class="line">    batch_time = AverageMeter()</span><br><span class="line">    data_time = AverageMeter()</span><br><span class="line">    losses = AverageMeter()</span><br><span class="line">    losses_x = AverageMeter()</span><br><span class="line">    losses_u = AverageMeter()</span><br><span class="line">    mask_probs = AverageMeter()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> args.no_progress:</span><br><span class="line">        p_bar = tqdm(<span class="built_in">range</span>(args.eval_step),</span><br><span class="line">                     disable=args.local_rank <span class="keyword">not</span> <span class="keyword">in</span> [-<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> batch_idx <span class="keyword">in</span> <span class="built_in">range</span>(args.eval_step):</span><br><span class="line">        <span class="comment"># 使用iter(next)读取指定次数的batch，而不通过Dataloader。Dataloader的长度也不同</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            inputs_x, targets_x = labeled_iter.<span class="built_in">next</span>()</span><br><span class="line">            <span class="comment">#print(inputs_x.shape) # torch.Size([64, 3, 32, 32])</span></span><br><span class="line">            <span class="comment">#print(targets_x.shape) # torch.Size([64])</span></span><br><span class="line">            <span class="comment">#print(targets_x)</span></span><br><span class="line">        <span class="keyword">except</span>: <span class="comment"># 当循环结束时，重新开始循环</span></span><br><span class="line">            <span class="keyword">if</span> args.world_size &gt; <span class="number">1</span>:</span><br><span class="line">                labeled_epoch += <span class="number">1</span></span><br><span class="line">                labeled_trainloader.sampler.set_epoch(labeled_epoch)</span><br><span class="line">            labeled_iter = <span class="built_in">iter</span>(labeled_trainloader)</span><br><span class="line">            inputs_x, targets_x = labeled_iter.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            (inputs_u_w, inputs_u_s), _ = unlabeled_iter.<span class="built_in">next</span>()</span><br><span class="line">            <span class="comment">#print(inputs_u_w.shape) #torch.Size([448, 3, 32, 32])</span></span><br><span class="line">            <span class="comment">#print(inputs_u_s.shape) #torch.Size([448, 3, 32, 32])</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">if</span> args.world_size &gt; <span class="number">1</span>:</span><br><span class="line">                unlabeled_epoch += <span class="number">1</span></span><br><span class="line">                unlabeled_trainloader.sampler.set_epoch(unlabeled_epoch)</span><br><span class="line">            unlabeled_iter = <span class="built_in">iter</span>(unlabeled_trainloader)</span><br><span class="line">            (inputs_u_w, inputs_u_s), _ = unlabeled_iter.<span class="built_in">next</span>() <span class="comment"># 忽略标签</span></span><br><span class="line"></span><br><span class="line">        data_time.update(time.time() - end)</span><br><span class="line">        batch_size = inputs_x.shape[<span class="number">0</span>] <span class="comment"># 64</span></span><br><span class="line">        <span class="comment"># 带标签的数据每批次有B个，无标签数据每批次有μB个(每个2张图像)，加起来就是(2μ+1)B个</span></span><br><span class="line">        inputs = interleave(</span><br><span class="line">            torch.cat((inputs_x, inputs_u_w, inputs_u_s)), <span class="number">2</span>*args.mu+<span class="number">1</span>).to(args.device)</span><br><span class="line">        <span class="comment"># print(inputs.shape) #torch.Size([960, 3, 32, 32]) 960=448+448+64 960=64*(2*7+1) 将数据合并一起</span></span><br><span class="line">        targets_x = targets_x.to(args.device)</span><br><span class="line">        <span class="comment"># print(targets_x.shape) #torch.Size([64])</span></span><br><span class="line">        </span><br><span class="line">        logits = model(inputs)</span><br><span class="line">        <span class="comment">#print(logits.shape) #torch.Size([960, 10])</span></span><br><span class="line">        logits = de_interleave(logits, <span class="number">2</span>*args.mu+<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#print(logits.shape) #torch.Size([960, 10])</span></span><br><span class="line">        logits_x = logits[:batch_size] <span class="comment"># 前B个</span></span><br><span class="line">        <span class="comment">#print(logits_x.shape) #torch.Size([64, 10])</span></span><br><span class="line">        logits_u_w, logits_u_s = logits[batch_size:].chunk(<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># torch.chunk 将输入Tensor拆分为特定数量的块。如果给定维度dim上的Tensor大小不能够被整除，则最后一个块会小于之前的块。</span></span><br><span class="line">        <span class="comment">#print(logits_u_w.shape) #torch.Size([448, 10]) </span></span><br><span class="line">        <span class="keyword">del</span> logits <span class="comment"># 省出内存，del删除的是变量，而不是数据。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 带标签数据的损失函数</span></span><br><span class="line">        Lx = F.cross_entropy(logits_x, targets_x, reduction=<span class="string">'mean'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 通过weak_augment样本计算伪标记pseudo label和mask，</span></span><br><span class="line">        <span class="comment"># 其中，mask用来筛选哪些样本最大预测概率超过阈值，可以拿来使用，哪些不能使用</span></span><br><span class="line"></span><br><span class="line">        pseudo_label = torch.softmax(logits_u_w.detach()/args.T, dim=-<span class="number">1</span>) <span class="comment"># 与 dim=2 等价，对某一维度的行进行softmax运算，和为1</span></span><br><span class="line">        <span class="comment"># Softmax为T＝1时的特例</span></span><br><span class="line">        max_probs, targets_u = torch.<span class="built_in">max</span>(pseudo_label, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#print(max_probs.shape) # torch.Size([448]) 448个最大概率值</span></span><br><span class="line">        <span class="comment">#print(targets_u.shape) # torch.Size([448]) 448个伪标签的值，实际上是pseudo_label中最大位置的索引</span></span><br><span class="line">        <span class="comment">#print(targets_u) #tensor([3, 5, 1 ....], device='cuda:0')</span></span><br><span class="line">        mask = max_probs.ge(args.threshold).<span class="built_in">float</span>() <span class="comment"># greater and equal（大于等于）</span></span><br><span class="line">        <span class="comment"># 比0.95大才说明这个标签置信度高，如果低于这个阈值，即使计算了交叉熵，也会被mask为0</span></span><br><span class="line">        <span class="comment"># torch.ge(a,b)逐个元素比较a，b的大小</span></span><br><span class="line">        <span class="comment"># print(mask.shape) #torch.Size([448]) 448个0/1</span></span><br><span class="line">        <span class="comment"># print(F.cross_entropy(logits_u_s, targets_u,reduction='none')) # reduction='none'不求平均，返回448个值</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 不带标签数据的损失函数</span></span><br><span class="line">        Lu = (F.cross_entropy(logits_u_s, targets_u,</span><br><span class="line">                              reduction=<span class="string">'none'</span>) * mask).mean()</span><br><span class="line"></span><br><span class="line">        loss = Lx + args.lambda_u * Lu <span class="comment"># 完整的损失函数</span></span><br></pre></td></tr></table></figure>
<p>其中torch.max的用法参考如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">24</span>).reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure>
<p>运行结果:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[-<span class="number">0.9135</span>,  <span class="number">1.3096</span>,  <span class="number">0.2803</span>, -<span class="number">0.9314</span>],</span><br><span class="line">         [-<span class="number">0.2687</span>, -<span class="number">0.0968</span>, -<span class="number">0.7156</span>, -<span class="number">0.8814</span>],</span><br><span class="line">         [-<span class="number">1.0099</span>,  <span class="number">1.6910</span>,  <span class="number">0.3458</span>, -<span class="number">0.6547</span>]],</span><br><span class="line"></span><br><span class="line">        [[-<span class="number">0.4334</span>, -<span class="number">0.0464</span>, -<span class="number">1.9236</span>,  <span class="number">0.3148</span>],</span><br><span class="line">         [ <span class="number">0.3628</span>, -<span class="number">0.7063</span>, -<span class="number">0.1750</span>,  <span class="number">1.5068</span>],</span><br><span class="line">         [ <span class="number">1.1270</span>, -<span class="number">0.9374</span>, -<span class="number">0.8419</span>, -<span class="number">0.0050</span>]]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = torch.softmax(a.detach()/<span class="number">1</span>, dim=-<span class="number">1</span>) <span class="comment"># 与 dim=2 等价，对某一维度的行进行softmax运算，和为1</span></span><br><span class="line"><span class="comment"># A = torch.softmax(a, dim=-1)</span></span><br><span class="line"><span class="built_in">print</span>(A)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[<span class="number">0.0689</span>, <span class="number">0.6362</span>, <span class="number">0.2273</span>, <span class="number">0.0677</span>],</span><br><span class="line">         [<span class="number">0.2968</span>, <span class="number">0.3525</span>, <span class="number">0.1899</span>, <span class="number">0.1608</span>],</span><br><span class="line">         [<span class="number">0.0472</span>, <span class="number">0.7025</span>, <span class="number">0.1830</span>, <span class="number">0.0673</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">0.2079</span>, <span class="number">0.3061</span>, <span class="number">0.0468</span>, <span class="number">0.4392</span>],</span><br><span class="line">         [<span class="number">0.1974</span>, <span class="number">0.0678</span>, <span class="number">0.1153</span>, <span class="number">0.6196</span>],</span><br><span class="line">         [<span class="number">0.6294</span>, <span class="number">0.0799</span>, <span class="number">0.0879</span>, <span class="number">0.2029</span>]]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">max_probs, targets_u = torch.<span class="built_in">max</span>(A, dim=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(max_probs)</span><br><span class="line"><span class="built_in">print</span>(max_probs.shape)</span><br><span class="line"><span class="built_in">print</span>(targets_u)</span><br><span class="line"><span class="built_in">print</span>(targets_u.shape)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">0.6362</span>, <span class="number">0.3525</span>, <span class="number">0.7025</span>],</span><br><span class="line">        [<span class="number">0.4392</span>, <span class="number">0.6196</span>, <span class="number">0.6294</span>]])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">3</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="comment"># cifar10标签序号从0-9，一共十类，IN数据集标签序号从1-16，一共十六类</span></span><br><span class="line"><span class="comment"># 而torch.max返回的最大位置索引是从0开始，这会导致序号对不上</span></span><br><span class="line"><span class="comment"># 上句话不对，加载数据集的时候已经把0标签排除了，所以不影响</span></span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<h2 id="模型保存与加载">模型保存与加载</h2>
<h3 id="模型保存过程">模型保存过程</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.local_rank <span class="keyword">in</span> [-<span class="number">1</span>, <span class="number">0</span>]:</span><br><span class="line">    test_loss, test_acc = test(args, test_loader, test_model, epoch)</span><br><span class="line">    </span><br><span class="line">    args.writer.add_scalar(<span class="string">'train/1.train_loss'</span>, losses.avg, epoch)</span><br><span class="line">    args.writer.add_scalar(<span class="string">'train/2.train_loss_x'</span>, losses_x.avg, epoch)</span><br><span class="line">    args.writer.add_scalar(<span class="string">'train/3.train_loss_u'</span>, losses_u.avg, epoch)</span><br><span class="line">    args.writer.add_scalar(<span class="string">'train/4.mask'</span>, mask_probs.avg, epoch)</span><br><span class="line">    args.writer.add_scalar(<span class="string">'test/1.test_acc'</span>, test_acc, epoch)</span><br><span class="line">    args.writer.add_scalar(<span class="string">'test/2.test_loss'</span>, test_loss, epoch)</span><br><span class="line">    </span><br><span class="line">    is_best = test_acc &gt; best_acc</span><br><span class="line">    best_acc = <span class="built_in">max</span>(test_acc, best_acc)</span><br><span class="line">    </span><br><span class="line">    model_to_save = model.module <span class="keyword">if</span> <span class="built_in">hasattr</span>(model, <span class="string">"module"</span>) <span class="keyword">else</span> model <span class="comment"># hasattr() 函数用于判断对象是否包含对应的属性</span></span><br><span class="line">    <span class="keyword">if</span> args.use_ema:</span><br><span class="line">        ema_to_save = ema_model.ema.module <span class="keyword">if</span> <span class="built_in">hasattr</span>(</span><br><span class="line">            ema_model.ema, <span class="string">"module"</span>) <span class="keyword">else</span> ema_model.ema</span><br><span class="line">        save_checkpoint({</span><br><span class="line">            <span class="string">'epoch'</span>: epoch + <span class="number">1</span>,</span><br><span class="line">            <span class="string">'state_dict'</span>: model_to_save.state_dict(),</span><br><span class="line">            <span class="string">'ema_state_dict'</span>: ema_to_save.state_dict() <span class="keyword">if</span> args.use_ema <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">            <span class="string">'acc'</span>: test_acc,</span><br><span class="line">            <span class="string">'best_acc'</span>: best_acc,</span><br><span class="line">            <span class="string">'optimizer'</span>: optimizer.state_dict(),</span><br><span class="line">            <span class="string">'scheduler'</span>: scheduler.state_dict(),</span><br><span class="line">        }, is_best, args.out)</span><br><span class="line">        </span><br><span class="line">        test_accs.append(test_acc)</span><br><span class="line">        logger.info(<span class="string">'Best top-1 acc: {:.3f}'</span>.<span class="built_in">format</span>(best_acc))</span><br><span class="line">        logger.info(<span class="string">'Mean top-1 acc: {:.3f}\n'</span>.<span class="built_in">format</span>(</span><br><span class="line">            np.mean(test_accs[-<span class="number">20</span>:])))</span><br></pre></td></tr></table></figure>
<h3 id="状态字典state_dict">状态字典：state_dict：</h3>
<p>在PyTorch中，<code>torch.nn.Module</code>模型的可学习参数（即权重和偏差）包含在模型的参数中，（使用<code>model.parameters()</code>可以进行访问）。
<code>state_dict</code>是Python字典对象，它将每一层映射到其参数张量。注意，只有具有可学习参数的层（如卷积层，线性层等）的模型才具有<code>state_dict</code>这一项。目标优化<code>torch.optim</code>也有<code>state_dict</code>属性，它包含有关优化器的状态信息，以及使用的超参数。
因为state_dict的对象是Python字典，所以它们可以很容易的保存、更新、修改和恢复，为PyTorch模型和优化器添加了大量模块。
下面通过从简单模型训练一个分类器中来了解一下<code>state_dict</code>的使用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TheModelClass</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(TheModelClass, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">model = TheModelClass()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化优化器</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印模型的状态字典</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Model's state_dict:"</span>)</span><br><span class="line"><span class="keyword">for</span> param_tensor <span class="keyword">in</span> model.state_dict():</span><br><span class="line">    <span class="built_in">print</span>(param_tensor, <span class="string">"\t"</span>, model.state_dict()[param_tensor].size())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印优化器的状态字典</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Optimizer's state_dict:"</span>)</span><br><span class="line"><span class="keyword">for</span> var_name <span class="keyword">in</span> optimizer.state_dict():</span><br><span class="line">    <span class="built_in">print</span>(var_name, <span class="string">"\t"</span>, optimizer.state_dict()[var_name])</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Model<span class="string">'s state_dict:</span></span><br><span class="line"><span class="string">conv1.weight 	 torch.Size([6, 3, 5, 5])</span></span><br><span class="line"><span class="string">conv1.bias 	 torch.Size([6])</span></span><br><span class="line"><span class="string">conv2.weight 	 torch.Size([16, 6, 5, 5])</span></span><br><span class="line"><span class="string">conv2.bias 	 torch.Size([16])</span></span><br><span class="line"><span class="string">fc1.weight 	 torch.Size([120, 400])</span></span><br><span class="line"><span class="string">fc1.bias 	 torch.Size([120])</span></span><br><span class="line"><span class="string">fc2.weight 	 torch.Size([84, 120])</span></span><br><span class="line"><span class="string">fc2.bias 	 torch.Size([84])</span></span><br><span class="line"><span class="string">fc3.weight 	 torch.Size([10, 84])</span></span><br><span class="line"><span class="string">fc3.bias 	 torch.Size([10])</span></span><br><span class="line"><span class="string">Optimizer'</span>s state_dict:</span><br><span class="line">state 	 {}</span><br><span class="line">param_groups 	 [{<span class="string">'lr'</span>: <span class="number">0.001</span>, <span class="string">'momentum'</span>: <span class="number">0.9</span>, <span class="string">'dampening'</span>: <span class="number">0</span>, <span class="string">'weight_decay'</span>: <span class="number">0</span>, <span class="string">'nesterov'</span>: <span class="literal">False</span>, <span class="string">'maximize'</span>: <span class="literal">False</span>, <span class="string">'params'</span>: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]}]</span><br></pre></td></tr></table></figure>
<h3 id="定义save_checkpoint保存完整模型">定义save_checkpoint保存完整模型</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">save_checkpoint</span>(<span class="params">state, is_best, checkpoint, filename=<span class="string">'checkpoint.pth.tar'</span></span>):</span><br><span class="line">    filepath = os.path.join(checkpoint, filename)</span><br><span class="line">    torch.save(state, filepath) <span class="comment"># 保存模型</span></span><br><span class="line">    <span class="keyword">if</span> is_best:</span><br><span class="line">        shutil.copyfile(filepath, os.path.join(checkpoint, <span class="string">'model_best.pth.tar'</span>)) <span class="comment"># 复制文件</span></span><br></pre></td></tr></table></figure>
<p>当保存好模型用来推断的时候，只需要保存模型学习到的参数，使用<code>torch.save()</code>函数来保存模型<code>state_dict</code>。
在 PyTorch 中最常见的模型保存使‘.pt’或者是‘.pth’作为模型文件扩展名。
在运行推理之前，务必调用<code>model.eval()</code>去设置 dropout 和 batch
normalization 层为评估模式。如果不这么做，可能导致模型推断结果不一致。
注意：
<code>load_state_dict()</code>函数只接受字典对象，而不是保存对象的路径。这就意味着在你传给<code>load_state_dict()</code>函数之前，你必须反序列化你保存的<code>state_dict</code>。例如，你无法通过
<code>model.load_state_dict(PATH)</code>来加载模型。</p>
<h3 id="保存和加载-checkpoint-用于推理继续训练">保存和加载 Checkpoint
用于推理/继续训练</h3>
<h4 id="保存checkpoint"><strong>保存Checkpoint：</strong></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">save_checkpoint({</span><br><span class="line">            <span class="string">'epoch'</span>: epoch + <span class="number">1</span>,</span><br><span class="line">            <span class="string">'state_dict'</span>: model_to_save.state_dict(),</span><br><span class="line">            <span class="string">'ema_state_dict'</span>: ema_to_save.state_dict() <span class="keyword">if</span> args.use_ema <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">            <span class="string">'acc'</span>: test_acc,</span><br><span class="line">            <span class="string">'best_acc'</span>: best_acc,</span><br><span class="line">            <span class="string">'optimizer'</span>: optimizer.state_dict(),</span><br><span class="line">            <span class="string">'scheduler'</span>: scheduler.state_dict(),</span><br><span class="line">        }, is_best, args.out)</span><br></pre></td></tr></table></figure>
<p>当保存成 Checkpoint
的时候，可用于推理或者是继续训练，保存的不仅仅是模型的<code>state_dict</code>。保存优化器的<code>state_dict</code>也很重要,
因为它包含作为模型训练更新的缓冲区和参数。你也许想保存其他项目，比如最新记录的训练损失，外部的<code>torch.nn.Embedding</code>层等等。
要保存多个组件，请在字典中组织它们并使用<code>torch.save()</code>来序列化字典。PyTorch
中常见的保存checkpoint是使用 .tar 文件扩展名。
要加载项目，首先需要初始化模型和优化器，然后使用<code>torch.load()</code>来加载本地字典。这里，你可以非常容易的通过简单查询字典来访问你所保存的项目。
请记住在运行推理之前，务必调用<code>model.eval()</code>去设置 dropout 和
batch normalization 为评估。如果不这样做，有可能得到不一致的推断结果。
如果你想要恢复训练，请调用<code>model.train()</code>以确保这些层处于训练模式。</p>
<h4 id="加载checkpoint"><strong>加载Checkpoint：</strong></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.resume:</span><br><span class="line">    logger.info(<span class="string">"==&gt; Resuming from checkpoint.."</span>)</span><br><span class="line">    <span class="comment"># os.path.isfile判断某一对象(需提供绝对路径)是否为文件</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.isfile(</span><br><span class="line">        args.resume), <span class="string">"Error: no checkpoint directory found!"</span></span><br><span class="line">    args.out = os.path.dirname(args.resume)</span><br><span class="line">    checkpoint = torch.load(args.resume)</span><br><span class="line">    best_acc = checkpoint[<span class="string">'best_acc'</span>]</span><br><span class="line">    args.start_epoch = checkpoint[<span class="string">'epoch'</span>]</span><br><span class="line">    model.load_state_dict(checkpoint[<span class="string">'state_dict'</span>])</span><br><span class="line">    <span class="keyword">if</span> args.use_ema:</span><br><span class="line">        ema_model.ema.load_state_dict(checkpoint[<span class="string">'ema_state_dict'</span>])</span><br><span class="line">    optimizer.load_state_dict(checkpoint[<span class="string">'optimizer'</span>])</span><br><span class="line">    scheduler.load_state_dict(checkpoint[<span class="string">'scheduler'</span>])</span><br></pre></td></tr></table></figure>
<h4 id="加载最优模型">加载最优模型：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自己写的</span></span><br><span class="line">filepath = os.path.join(args.out, <span class="string">'model_best.pth.tar'</span>)</span><br><span class="line">    <span class="keyword">assert</span> os.path.isfile(filepath), <span class="string">"Error: no model_best directory found!"</span></span><br><span class="line">    model.load_state_dict(torch.load(filepath)[<span class="string">'state_dict'</span>])</span><br><span class="line">    <span class="keyword">if</span> args.use_ema:</span><br><span class="line">        ema_model.ema.load_state_dict(torch.load(filepath)[<span class="string">'ema_state_dict'</span>])</span><br></pre></td></tr></table></figure>
<h2 id="accuracy">accuracy</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># outputs.shape为 [batch_size, category_count]</span></span><br><span class="line"><span class="comment"># targets.shape为 [batch_size]，每个样本中只有一个真实的类</span></span><br><span class="line"><span class="comment"># topk是要包含在精度中的类的元组，例如topk=(1,5)，则包含五个类</span></span><br><span class="line"><span class="comment"># topk必须是一个元组，所以给出一个数字，不要忘记逗号</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">output, target, topk=(<span class="params"><span class="number">1</span>,</span>)</span>):</span><br><span class="line">    <span class="string">"""Computes the precision@k for the specified values of k"""</span></span><br><span class="line">    maxk = <span class="built_in">max</span>(topk)</span><br><span class="line">    <span class="comment"># size函数：总元素的个数</span></span><br><span class="line">    batch_size = target.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># topk函数output的d维度中选取前k个最大的值，下式为前maxk个</span></span><br><span class="line">    <span class="comment"># _, pred = output.topk(maxk, 1, True, True)</span></span><br><span class="line">    <span class="comment"># output.shape为 [batch_size, category_count]，dim=1，所以我们为每个batch选择最大的类别数</span></span><br><span class="line">    <span class="comment"># 输入结果为[ batch_size,maxk]</span></span><br><span class="line">    <span class="comment"># topk返回结果的元组 (values, indexes) (值，索引)</span></span><br><span class="line">    <span class="comment"># 我们只需要索引(pred)</span></span><br><span class="line">    _, pred = output.topk(maxk, dim=<span class="number">1</span>, largest=<span class="literal">True</span>, <span class="built_in">sorted</span>=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 然后我们将索引转置为 [maxk, batch_size]</span></span><br><span class="line">    pred = pred.t()</span><br><span class="line">    correct = pred.eq(target.reshape(<span class="number">1</span>, -<span class="number">1</span>).expand_as(pred))</span><br><span class="line">    <span class="comment"># torch.eq对两个张量Tensor进行逐元素的比较，若相同位置的两个元素相同，则返回True；若不同，返回False</span></span><br><span class="line">    <span class="comment"># 将target展平，并将target扩展成类似于pred</span></span><br><span class="line">    <span class="comment"># target [batch_size] 变成 [1,batch_size]</span></span><br><span class="line">    <span class="comment"># target [1,batch_size] 通过广播？重复相同的类maxk次，从 [1,batch_size] 变为 [maxk, batch_size]</span></span><br><span class="line">    <span class="comment"># 当将索引(pred)与扩展后的target比较时，即torch.eq，会得到形状为 [maxk, batch_size] 的矩阵correct</span></span><br><span class="line">    <span class="string">""" correct=([[0, 0, 1,  ..., 0, 0, 0],</span></span><br><span class="line"><span class="string">         [1, 0, 0,  ..., 0, 0, 0],</span></span><br><span class="line"><span class="string">         [0, 0, 0,  ..., 1, 0, 0],</span></span><br><span class="line"><span class="string">         [0, 0, 0,  ..., 0, 0, 0],</span></span><br><span class="line"><span class="string">         [0, 1, 0,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.uint8) """</span></span><br><span class="line"></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> topk:</span><br><span class="line">        correct_k = correct[:k].reshape(-<span class="number">1</span>).<span class="built_in">float</span>().<span class="built_in">sum</span>(<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># correct[:k]：[maxk, batch_size] -&gt; [k, batch_size]</span></span><br><span class="line">        <span class="comment"># .reshape(-1)：[k, batch_size] -&gt; [k*batch_size]</span></span><br><span class="line">        <span class="comment"># .sum(0)：[k*batch_size] -&gt; [1]</span></span><br><span class="line">        res.append(correct_k.mul_(<span class="number">100.0</span> / batch_size))</span><br><span class="line">        <span class="comment"># mul 乘法</span></span><br><span class="line">        <span class="comment"># 所有带_都是inplace，意思就是操作后，原数也会改动</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>topk函数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -&gt; (Tensor, LongTensor)</span><br></pre></td></tr></table></figure>
<p>input (Tensor)：输入张量，一个tensor数据 k
(int)：指明是得到前k个数据以及其index dim (int, optional)：
指定在哪个维度上排序， 默认是最后一个维度 largest (bool,
optional)：如果为True，按照大到小排序； 如果为False，按照小到大排序
sorted (bool, optional) ：控制返回值是否排序 out (tuple,
optional)：可选输出张量 (Tensor, LongTensor)</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">1</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(a.shape)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line">torch.Size([<span class="number">5</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">correct_1 = a[:<span class="number">1</span>].reshape(-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(correct_1.shape)</span><br><span class="line"><span class="built_in">print</span>(correct_1)</span><br><span class="line">correct_1 = correct_1.<span class="built_in">float</span>().<span class="built_in">sum</span>(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(correct_1.shape)</span><br><span class="line"><span class="built_in">print</span>(correct_1)</span><br><span class="line">correct_1.mul_(<span class="number">100.0</span> / <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(correct_1.shape)</span><br><span class="line"><span class="built_in">print</span>(correct_1)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">4</span>])</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">torch.Size([])</span><br><span class="line">tensor(<span class="number">2.</span>)</span><br><span class="line">torch.Size([])</span><br><span class="line">tensor(<span class="number">50.</span>) <span class="comment"># top_1 = 50%</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">correct_5 = a[:<span class="number">5</span>].reshape(-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(correct_5.shape)</span><br><span class="line"><span class="built_in">print</span>(correct_5)</span><br><span class="line">correct_5 = correct_5.<span class="built_in">float</span>().<span class="built_in">sum</span>(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(correct_5.shape)</span><br><span class="line"><span class="built_in">print</span>(correct_5)</span><br><span class="line">correct_5.mul_(<span class="number">100.0</span> / <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(correct_5.shape)</span><br><span class="line"><span class="built_in">print</span>(correct_5)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">20</span>])</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">torch.Size([])</span><br><span class="line">tensor(<span class="number">4.</span>)</span><br><span class="line">torch.Size([])</span><br><span class="line">tensor(<span class="number">100.</span>) <span class="comment"># top_5 = 100%</span></span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>原作者： </strong>Ahtong
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://blog.tongorz.me/article/2022111294813030.html" title="Fixmatch主要代码注释">https://blog.tongorz.me/article/2022111294813030.html</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
              <a href="/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" rel="tag"><i class="fa fa-tag"></i> 图像分类</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
            </div>
            <div class="post-nav-item">
                <a href="/article/20230120c94939a8.html" rel="next" title="用于高光谱图像分类的折叠谱生成对抗网络">
                  用于高光谱图像分类的折叠谱生成对抗网络 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  
  <div class="comments giscus-container">
  </div>
  
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Ahtong</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">94k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">5:15</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div><script color="0,0,0" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.icodeq.com/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



  <script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/moment.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/moment-precise-range-plugin@1.3.0/moment-precise-range.min.js"></script>
  <script>
    function timer() {
      var ages = moment.preciseDiff(moment(),moment(20240130100000,"YYYYMMDDhmmss"));
      ages = ages.replace(/years?/, "年");
      ages = ages.replace(/months?/, "月");
      ages = ages.replace(/days?/, "天");
      ages = ages.replace(/hours?/, "小时");
      ages = ages.replace(/minutes?/, "分");
      ages = ages.replace(/seconds?/, "秒");
      ages = ages.replace(/\d+/g, '<span style="color:#1890ff">$&</span>');
      div.innerHTML = `本站已稳定运行 ${ages}`;
    }
    var div = document.createElement("div");
    var copyright = document.querySelector(".copyright");
    document.querySelector(".footer-inner").insertBefore(div, copyright.nextSibling);
    timer();
    setInterval("timer()",1000)
  </script>

  
<script class="next-config" data-name="giscus" type="application/json">{"enable":true,"repo":"7ongOrz/comments","repo_id":"R_kgDOLMZT5A","category":"Announcements","category_id":"DIC_kwDOLMZT5M4CdAO0","mapping":"url","reactions_enabled":1,"emit_metadata":1,"theme":"preferred_color_scheme","lang":"zh-CN","crossorigin":"anonymous","input_position":"top","loading":"lazy"}</script>

<script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.page.comments) return;

  NexT.utils.loadComments('.giscus-container')
    .then(() => NexT.utils.getScript('https://giscus.app/client.js', {
      attributes: {
        async                   : true,
        crossOrigin             : 'anonymous',
        'data-repo'             : CONFIG.giscus.repo,
        'data-repo-id'          : CONFIG.giscus.repo_id,
        'data-category'         : CONFIG.giscus.category,
        'data-category-id'      : CONFIG.giscus.category_id,
        'data-mapping'          : CONFIG.giscus.mapping,
        'data-reactions-enabled': CONFIG.giscus.reactions_enabled,
        'data-emit-metadata'    : CONFIG.giscus.emit_metadata,
        'data-theme'            : CONFIG.giscus.theme,
        'data-lang'             : CONFIG.giscus.lang,
        'data-input-position'   : CONFIG.giscus.input_position,
        'data-loading'          : CONFIG.giscus.loading
      },
      parentNode: document.querySelector('.giscus-container')
    }));
});
</script>

</body>
</html>
